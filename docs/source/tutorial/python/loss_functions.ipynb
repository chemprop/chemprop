{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning import pytorch as pl\n",
    "import numpy as np\n",
    "from chemprop import data, models, nn\n",
    "from chemprop.nn.loss import LossFunctionRegistry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chemprop provides several loss functions. The derivatives of these differentiable functions are used to update the model weights. Users only need to select the loss function to use. The rest of the details are handled by Chemprop and the lightning trainer, which reports the training loss during model fitting (training). Note that the loss function is not used during evaluation on the validation or test sets. A [metric](./metrics.ipynb) is used in those cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse\n",
      "bounded-mse\n",
      "mve\n",
      "evidential\n",
      "bce\n",
      "ce\n",
      "binary-mcc\n",
      "multiclass-mcc\n",
      "binary-dirichlet\n",
      "multiclass-dirichlet\n",
      "sid\n",
      "earthmovers\n",
      "wasserstein\n"
     ]
    }
   ],
   "source": [
    "for lossfunction in LossFunctionRegistry:\n",
    "    print(lossfunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model can make predictions of multiple targets/tasks at the same time. For example, a model may predict both solubility and melting point. Task weights can be specified when some of the tasks are more important to get accurate than others. The weight for each task defaults to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss(task_weights=[[0.10000000149011612, 0.5, 1.0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chemprop.nn.loss import MSELoss\n",
    "\n",
    "predictor = nn.RegressionFFN(criterion=MSELoss(task_weights=[0.1, 0.5, 1.0]))\n",
    "model = models.MPNN(nn.BondMessagePassing(), nn.MeanAggregation(), predictor)\n",
    "predictor.criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean squared error and bounded mean square error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MSELoss` is the default loss function for regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss(task_weights=[[1.0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = nn.RegressionFFN()\n",
    "model = models.MPNN(nn.BondMessagePassing(), nn.MeanAggregation(), predictor)\n",
    "predictor.criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BoundedMSELoss` is useful when the target values have \"less than\" or \"greater than\" behavior, e.g. the prediction is correct as long as it is below/above a target value. Datapoints have a less than/greater than property that keeps track of bounded targets. Note that, like target values, the less than and greater than masks used to make datapoints are 1-D numpy arrays of bools instead of a single bool. This is because a single datapoint can have multiple target values and the less than/greater than masks are defined for each target value separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from chemprop.nn.loss import BoundedMSELoss\n",
    "\n",
    "smis = [\"C\" * i for i in range(1, 6)]\n",
    "ys = np.random.rand(len(smis), 1)\n",
    "lt_mask = np.array([[True], [False], [False], [False], [True]])\n",
    "gt_mask = np.array([[False], [True], [False], [True], [False]])\n",
    "datapoints = [\n",
    "    data.MoleculeDatapoint.from_smi(smi, y, lt_mask=lt, gt_mask=gt)\n",
    "    for smi, y, lt, gt in zip(smis, ys, lt_mask, gt_mask)\n",
    "]\n",
    "bounded_dataset = data.MoleculeDataset(datapoints)\n",
    "bounded_dataset.lt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = nn.RegressionFFN(criterion=BoundedMSELoss())\n",
    "model = models.MPNN(nn.BondMessagePassing(), nn.MeanAggregation(), predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary cross entropy and cross entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BCELoss` is the default loss function for binary classification and `CrossEntropyLoss` is the default for multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCELoss(task_weights=[[1.0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = nn.BinaryClassificationFFN()\n",
    "predictor.criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss(task_weights=[[1.0, 1.0, 1.0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = nn.MulticlassClassificationFFN(n_classes=3)\n",
    "predictor.criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matthews correlation coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCC loss is useful for imbalanced classification data. More details coming soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemprop.nn.loss import BinaryMCCLoss, MulticlassMCCLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty and spectral loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta versions of metrics for uncertainty and spectra prediction will be finalized for v2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemprop.nn.loss import MVELoss, EvidentialLoss, BinaryDirichletLoss, MulticlassDirichletLoss\n",
    "from chemprop.nn.loss import SIDLoss, WassersteinLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A custom loss function can be made by inheriting from `LossFunction` and overwriting the methods as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from chemprop.nn.loss import LossFunction\n",
    "\n",
    "\n",
    "class CustomLoss(LossFunction):\n",
    "    def __init__(self, task_weights=None, norm: float = 1.0):\n",
    "        super().__init__(task_weights)\n",
    "        norm = torch.as_tensor(norm)\n",
    "        self.register_buffer(\"norm\", norm)\n",
    "\n",
    "    def _calc_unreduced_loss(self, preds, targets, mask, weights, lt_mask, gt_mask) -> Tensor:\n",
    "        return torch.sum((preds - targets) ** 2) / self.norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
