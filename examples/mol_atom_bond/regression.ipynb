{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5267af8d",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chemprop/chemprop/blob/main/examples/mol_atom_bond/regression.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f163e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install chemprop from GitHub if running in Google Colab\n",
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    try:\n",
    "        import chemprop\n",
    "    except ImportError:\n",
    "        !git clone https://github.com/chemprop/chemprop.git\n",
    "        %cd chemprop\n",
    "        !pip install .\n",
    "        %cd examples/mol_atom_bond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab97f25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from pathlib import Path\n",
    "\n",
    "from lightning import pytorch as pl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from chemprop import data, featurizers, models, nn\n",
    "\n",
    "columns = [\"smiles\", \"mol_y1\", \"mol_y2\", \"atom_y1\", \"atom_y2\", \"bond_y1\", \"bond_y2\", \"weight\"]\n",
    "chemprop_dir = Path.cwd().parent.parent\n",
    "data_dir = chemprop_dir / \"tests\" / \"data\" / \"mol_atom_bond\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883bfa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ds = np.load(data_dir / \"descriptors.npz\")[\"arr_0\"]\n",
    "V_fs = np.load(data_dir / \"atom_features_descriptors.npz\")\n",
    "V_fs = [V_fs[f\"arr_{i}\"] for i in range(len(V_fs))]\n",
    "V_ds = V_fs\n",
    "E_fs = np.load(data_dir / \"bond_features_descriptors.npz\")\n",
    "E_fs = [E_fs[f\"arr_{i}\"] for i in range(len(E_fs))]\n",
    "E_ds = [np.repeat(E_f, repeats=2, axis=0) for E_f in E_fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64e34f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = pd.read_csv(data_dir / \"regression.csv\")\n",
    "smis = df_input.loc[:, columns[0]].values\n",
    "mol_ys = df_input.loc[:, columns[1:3]].values\n",
    "atoms_ys = df_input.loc[:, columns[3:5]].values\n",
    "bonds_ys = df_input.loc[:, columns[5:7]].values\n",
    "weights = df_input.loc[:, columns[7]].values\n",
    "\n",
    "atoms_ys = [\n",
    "    np.array([ast.literal_eval(atom_y) for atom_y in atom_ys], dtype=float).T\n",
    "    for atom_ys in atoms_ys\n",
    "]\n",
    "bonds_ys = [\n",
    "    np.array([ast.literal_eval(bond_y) for bond_y in bond_ys], dtype=float).T\n",
    "    for bond_ys in bonds_ys\n",
    "]\n",
    "\n",
    "datapoints = [\n",
    "    data.MolAtomBondDatapoint.from_smi(\n",
    "        smi,\n",
    "        keep_h=True,\n",
    "        add_h=False,\n",
    "        reorder_atoms=True,\n",
    "        y=mol_ys[i],\n",
    "        atom_y=atoms_ys[i],\n",
    "        bond_y=bonds_ys[i],\n",
    "        weight=weights[i],\n",
    "        x_d=x_ds[i],\n",
    "        V_f=V_fs[i],\n",
    "        V_d=V_ds[i],\n",
    "        E_f=E_fs[i],\n",
    "        E_d=E_ds[i],\n",
    "    )\n",
    "    for i, smi in enumerate(smis)\n",
    "]\n",
    "\n",
    "featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer(\n",
    "    extra_atom_fdim=atoms_ys[0].shape[1], extra_bond_fdim=bonds_ys[0].shape[1]\n",
    ")\n",
    "\n",
    "train_dataset = data.MolAtomBondDataset(datapoints, featurizer=featurizer)\n",
    "val_dataset = data.MolAtomBondDataset(datapoints, featurizer=featurizer)\n",
    "test_dataset = data.MolAtomBondDataset(datapoints, featurizer=featurizer)\n",
    "predict_dataset = data.MolAtomBondDataset(datapoints, featurizer=featurizer)\n",
    "\n",
    "V_f_scaler = train_dataset.normalize_inputs(\"V_f\")\n",
    "E_f_scaler = train_dataset.normalize_inputs(\"E_f\")\n",
    "V_d_scaler = train_dataset.normalize_inputs(\"V_d\")\n",
    "E_d_scaler = train_dataset.normalize_inputs(\"E_d\")\n",
    "val_dataset.normalize_inputs(\"V_f\", V_f_scaler)\n",
    "val_dataset.normalize_inputs(\"E_f\", E_f_scaler)\n",
    "val_dataset.normalize_inputs(\"V_d\", V_d_scaler)\n",
    "val_dataset.normalize_inputs(\"E_d\", E_d_scaler)\n",
    "\n",
    "V_f_transform = nn.ScaleTransform.from_standard_scaler(\n",
    "    V_f_scaler, pad=(featurizer.atom_fdim - featurizer.extra_atom_fdim)\n",
    ")\n",
    "E_f_transform = nn.ScaleTransform.from_standard_scaler(\n",
    "    E_f_scaler, pad=(featurizer.bond_fdim - featurizer.extra_bond_fdim)\n",
    ")\n",
    "graph_transform = nn.GraphTransform(V_f_transform, E_f_transform)\n",
    "V_d_transform = nn.ScaleTransform.from_standard_scaler(V_d_scaler)\n",
    "E_d_transform = nn.ScaleTransform.from_standard_scaler(E_d_scaler)\n",
    "\n",
    "X_d_scaler = train_dataset.normalize_inputs(\"X_d\")\n",
    "val_dataset.normalize_inputs(\"X_d\", X_d_scaler)\n",
    "X_d_transform = nn.ScaleTransform.from_standard_scaler(X_d_scaler)\n",
    "\n",
    "mol_target_scaler = train_dataset.normalize_targets(\"mol\")\n",
    "atom_target_scaler = train_dataset.normalize_targets(\"atom\")\n",
    "bond_target_scaler = train_dataset.normalize_targets(\"bond\")\n",
    "val_dataset.normalize_targets(\"mol\", mol_target_scaler)\n",
    "val_dataset.normalize_targets(\"atom\", atom_target_scaler)\n",
    "val_dataset.normalize_targets(\"bond\", bond_target_scaler)\n",
    "mol_target_transform = nn.UnscaleTransform.from_standard_scaler(mol_target_scaler)\n",
    "atom_target_transform = nn.UnscaleTransform.from_standard_scaler(atom_target_scaler)\n",
    "bond_target_transform = nn.UnscaleTransform.from_standard_scaler(bond_target_scaler)\n",
    "\n",
    "train_dataloader = data.build_dataloader(train_dataset, shuffle=True, batch_size=4)\n",
    "val_dataloader = data.build_dataloader(val_dataset, shuffle=False, batch_size=4)\n",
    "test_dataloader = data.build_dataloader(test_dataset, shuffle=False, batch_size=4)\n",
    "predict_dataloader = data.build_dataloader(predict_dataset, shuffle=False, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cede1449",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = nn.MABBondMessagePassing(\n",
    "    d_v=featurizer.atom_fdim,\n",
    "    d_e=featurizer.bond_fdim,\n",
    "    d_h=100,\n",
    "    d_vd=V_ds[0].shape[1],\n",
    "    d_ed=E_ds[0].shape[1],\n",
    "    dropout=0.1,\n",
    "    activation=\"tanh\",\n",
    "    depth=4,\n",
    "    graph_transform=graph_transform,\n",
    "    V_d_transform=V_d_transform,\n",
    "    E_d_transform=E_d_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "256c1cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [nn.MAE(), nn.RMSE()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5da5beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = nn.NormAggregation(norm=10)\n",
    "mol_predictor = nn.RegressionFFN(\n",
    "    input_dim=mp.output_dims[0] + x_ds.shape[1],\n",
    "    n_tasks=mol_ys.shape[1],\n",
    "    output_transform=mol_target_transform,\n",
    "    criterion=nn.MSE(task_weights=[0.5, 0.1]),\n",
    ")\n",
    "atom_predictor = nn.RegressionFFN(\n",
    "    input_dim=mp.output_dims[0],\n",
    "    n_tasks=atoms_ys[0].shape[1],\n",
    "    output_transform=atom_target_transform,\n",
    ")\n",
    "bond_predictor = nn.RegressionFFN(\n",
    "    input_dim=(mp.output_dims[1] * 2),\n",
    "    n_tasks=bonds_ys[0].shape[1],\n",
    "    output_transform=bond_target_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab1d3bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.MolAtomBondMPNN(\n",
    "    message_passing=mp,\n",
    "    agg=agg,\n",
    "    mol_predictor=mol_predictor,\n",
    "    atom_predictor=atom_predictor,\n",
    "    bond_predictor=bond_predictor,\n",
    "    batch_norm=True,\n",
    "    metrics=metrics,\n",
    "    X_d_transform=X_d_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b9f9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolAtomBondMPNN(\n",
       "  (message_passing): MABBondMessagePassing(\n",
       "    (W_i): Linear(in_features=90, out_features=100, bias=False)\n",
       "    (W_h): Linear(in_features=100, out_features=100, bias=False)\n",
       "    (W_vo): Linear(in_features=174, out_features=100, bias=True)\n",
       "    (W_vd): Linear(in_features=102, out_features=102, bias=True)\n",
       "    (W_eo): Linear(in_features=116, out_features=100, bias=True)\n",
       "    (W_ed): Linear(in_features=102, out_features=102, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (tau): Tanh()\n",
       "    (V_d_transform): ScaleTransform()\n",
       "    (E_d_transform): ScaleTransform()\n",
       "    (graph_transform): GraphTransform(\n",
       "      (V_transform): ScaleTransform()\n",
       "      (E_transform): ScaleTransform()\n",
       "    )\n",
       "  )\n",
       "  (agg): NormAggregation()\n",
       "  (mol_predictor): RegressionFFN(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=104, out_features=300, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): MSE(task_weights=[[0.5, 0.10000000149011612]])\n",
       "    (output_transform): UnscaleTransform()\n",
       "  )\n",
       "  (atom_predictor): RegressionFFN(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=102, out_features=300, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): MSE(task_weights=[[1.0, 1.0]])\n",
       "    (output_transform): UnscaleTransform()\n",
       "  )\n",
       "  (bond_predictor): RegressionFFN(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=204, out_features=300, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): MSE(task_weights=[[1.0, 1.0]])\n",
       "    (output_transform): UnscaleTransform()\n",
       "  )\n",
       "  (bns): ModuleList(\n",
       "    (0-2): 3 x BatchNorm1d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (X_d_transform): ScaleTransform()\n",
       "  (metricss): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): MAE(task_weights=[[1.0]])\n",
       "      (1): RMSE(task_weights=[[1.0]])\n",
       "      (2): MSE(task_weights=[[0.5, 0.10000000149011612]])\n",
       "    )\n",
       "    (1-2): 2 x ModuleList(\n",
       "      (0): MAE(task_weights=[[1.0]])\n",
       "      (1): RMSE(task_weights=[[1.0]])\n",
       "      (2): MSE(task_weights=[[1.0, 1.0]])\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "132b16dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 2)\n",
      "(2, 2, 2)\n",
      "(1, 1, 1)\n",
      "(MSE(task_weights=[[0.5, 0.10000000149011612]]), MSE(task_weights=[[1.0, 1.0]]), MSE(task_weights=[[1.0, 1.0]]))\n"
     ]
    }
   ],
   "source": [
    "print(model.output_dimss)\n",
    "print(model.n_taskss)\n",
    "print(model.n_targetss)\n",
    "print(model.criterions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3051d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpointing = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-{epoch}-{val_loss:.2f}\",\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=False,\n",
    "    enable_checkpointing=True,\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=20,\n",
    "    callbacks=[checkpointing],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb456c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf checkpoints/\n",
    "! rm temp.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5f4f787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\n",
      "  | Name            | Type                  | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | message_passing | MABBondMessagePassing | 69.2 K | train\n",
      "1 | agg             | NormAggregation       | 0      | train\n",
      "2 | mol_predictor   | RegressionFFN         | 32.1 K | train\n",
      "3 | atom_predictor  | RegressionFFN         | 31.5 K | train\n",
      "4 | bond_predictor  | RegressionFFN         | 62.1 K | train\n",
      "5 | bns             | ModuleList            | 612    | train\n",
      "6 | X_d_transform   | ScaleTransform        | 0      | train\n",
      "7 | metricss        | ModuleList            | 0      | train\n",
      "------------------------------------------------------------------\n",
      "195 K     Trainable params\n",
      "0         Non-trainable params\n",
      "195 K     Total params\n",
      "0.782     Total estimated model params size (MB)\n",
      "63        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 3/3 [00:00<00:00, 13.09it/s, mol_train_loss_step=0.0121, atom_train_loss_step=0.0669, bond_train_loss_step=0.219, train_loss_step=0.298, mol_val_loss=0.0259, atom_val_loss=0.0127, bond_val_loss=0.0394, val_loss=0.115, mol_train_loss_epoch=0.0161, atom_train_loss_epoch=0.0351, bond_train_loss_epoch=0.0896, train_loss_epoch=0.151]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 3/3 [00:00<00:00, 11.57it/s, mol_train_loss_step=0.0121, atom_train_loss_step=0.0669, bond_train_loss_step=0.219, train_loss_step=0.298, mol_val_loss=0.0259, atom_val_loss=0.0127, bond_val_loss=0.0394, val_loss=0.115, mol_train_loss_epoch=0.0161, atom_train_loss_epoch=0.0351, bond_train_loss_epoch=0.0896, train_loss_epoch=0.151]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d177eb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at /home/knathan/chemprop/examples/mol_atom_bond/checkpoints/best-epoch=18-val_loss=0.11.ckpt\n",
      "Loaded model weights from the checkpoint at /home/knathan/chemprop/examples/mol_atom_bond/checkpoints/best-epoch=18-val_loss=0.11.ckpt\n",
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 41.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       atom_test/mae       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3877747654914856     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      atom_test/rmse       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7296686172485352     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       bond_test/mae       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.575097918510437     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      bond_test/rmse       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.2251358032226562     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       mol_test/mae        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     4.022435188293457     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       mol_test/rmse       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     6.951046943664551     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      atom_test/mae      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3877747654914856    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     atom_test/rmse      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7296686172485352    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      bond_test/mae      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.575097918510437    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     bond_test/rmse      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.2251358032226562    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      mol_test/mae       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    4.022435188293457    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      mol_test/rmse      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    6.951046943664551    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.test(dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13ce67b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 109.37it/s]\n"
     ]
    }
   ],
   "source": [
    "predss = trainer.predict(model, predict_dataloader)\n",
    "mol_preds, atom_preds, bond_preds = (torch.concat(tensors) for tensors in zip(*predss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "854e213d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolAtomBondMPNN(\n",
       "  (message_passing): MABBondMessagePassing(\n",
       "    (W_i): Linear(in_features=90, out_features=100, bias=False)\n",
       "    (W_h): Linear(in_features=100, out_features=100, bias=False)\n",
       "    (W_vo): Linear(in_features=174, out_features=100, bias=True)\n",
       "    (W_vd): Linear(in_features=102, out_features=102, bias=True)\n",
       "    (W_eo): Linear(in_features=116, out_features=100, bias=True)\n",
       "    (W_ed): Linear(in_features=102, out_features=102, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (tau): Tanh()\n",
       "    (V_d_transform): ScaleTransform()\n",
       "    (E_d_transform): ScaleTransform()\n",
       "    (graph_transform): GraphTransform(\n",
       "      (V_transform): ScaleTransform()\n",
       "      (E_transform): ScaleTransform()\n",
       "    )\n",
       "  )\n",
       "  (agg): NormAggregation()\n",
       "  (mol_predictor): RegressionFFN(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=104, out_features=300, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): MSE(task_weights=[[0.5, 0.10000000149011612]])\n",
       "    (output_transform): UnscaleTransform()\n",
       "  )\n",
       "  (atom_predictor): RegressionFFN(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=102, out_features=300, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): MSE(task_weights=[[1.0, 1.0]])\n",
       "    (output_transform): UnscaleTransform()\n",
       "  )\n",
       "  (bond_predictor): RegressionFFN(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=204, out_features=300, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): MSE(task_weights=[[1.0, 1.0]])\n",
       "    (output_transform): UnscaleTransform()\n",
       "  )\n",
       "  (bns): ModuleList(\n",
       "    (0-2): 3 x BatchNorm1d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (X_d_transform): ScaleTransform()\n",
       "  (metricss): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): MAE(task_weights=[[1.0]])\n",
       "      (1): RMSE(task_weights=[[1.0]])\n",
       "      (2): MSE(task_weights=[[0.5, 0.10000000149011612]])\n",
       "    )\n",
       "    (1-2): 2 x ModuleList(\n",
       "      (0): MAE(task_weights=[[1.0]])\n",
       "      (1): RMSE(task_weights=[[1.0]])\n",
       "      (2): MSE(task_weights=[[1.0, 1.0]])\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.utils.save_model(\"temp.pt\", model)\n",
    "models.MolAtomBondMPNN.load_from_file(\"temp.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5d8fe04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolAtomBondMPNN(\n",
       "  (message_passing): MABBondMessagePassing(\n",
       "    (W_i): Linear(in_features=90, out_features=100, bias=False)\n",
       "    (W_h): Linear(in_features=100, out_features=100, bias=False)\n",
       "    (W_vo): Linear(in_features=174, out_features=100, bias=True)\n",
       "    (W_vd): Linear(in_features=102, out_features=102, bias=True)\n",
       "    (W_eo): Linear(in_features=116, out_features=100, bias=True)\n",
       "    (W_ed): Linear(in_features=102, out_features=102, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (tau): Tanh()\n",
       "    (V_d_transform): ScaleTransform()\n",
       "    (E_d_transform): ScaleTransform()\n",
       "    (graph_transform): GraphTransform(\n",
       "      (V_transform): ScaleTransform()\n",
       "      (E_transform): ScaleTransform()\n",
       "    )\n",
       "  )\n",
       "  (agg): NormAggregation()\n",
       "  (mol_predictor): RegressionFFN(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=104, out_features=300, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): MSE(task_weights=[[0.5, 0.10000000149011612]])\n",
       "    (output_transform): UnscaleTransform()\n",
       "  )\n",
       "  (atom_predictor): RegressionFFN(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=102, out_features=300, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): MSE(task_weights=[[1.0, 1.0]])\n",
       "    (output_transform): UnscaleTransform()\n",
       "  )\n",
       "  (bond_predictor): RegressionFFN(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=204, out_features=300, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): MSE(task_weights=[[1.0, 1.0]])\n",
       "    (output_transform): UnscaleTransform()\n",
       "  )\n",
       "  (bns): ModuleList(\n",
       "    (0-2): 3 x BatchNorm1d(102, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (X_d_transform): ScaleTransform()\n",
       "  (metricss): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): MAE(task_weights=[[1.0]])\n",
       "      (1): RMSE(task_weights=[[1.0]])\n",
       "      (2): MSE(task_weights=[[0.5, 0.10000000149011612]])\n",
       "    )\n",
       "    (1-2): 2 x ModuleList(\n",
       "      (0): MAE(task_weights=[[1.0]])\n",
       "      (1): RMSE(task_weights=[[1.0]])\n",
       "      (2): MSE(task_weights=[[1.0, 1.0]])\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.MolAtomBondMPNN.load_from_checkpoint(\"checkpoints/last.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
