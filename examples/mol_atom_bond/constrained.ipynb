{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a18a22a9",
   "metadata": {},
   "source": [
    "# Constrained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660f198a",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chemprop/chemprop/blob/main/examples/mol_atom_bond/constrained.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14c413f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install chemprop from GitHub if running in Google Colab\n",
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    try:\n",
    "        import chemprop\n",
    "    except ImportError:\n",
    "        !git clone https://github.com/chemprop/chemprop.git\n",
    "        %cd chemprop\n",
    "        !pip install .\n",
    "        %cd examples/mol_atom_bond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e816bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from pathlib import Path\n",
    "\n",
    "from lightning import pytorch as pl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from chemprop import data, featurizers, models, nn\n",
    "\n",
    "columns = [\"smiles\", \"mol_y\", \"atom_y1\", \"atom_y2\", \"bond_y1\", \"bond_y2\"]\n",
    "chemprop_dir = Path.cwd().parent.parent\n",
    "data_dir = chemprop_dir / \"tests\" / \"data\" / \"mol_atom_bond\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64e34f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = pd.read_csv(data_dir / \"constrained_regression.csv\")\n",
    "smis = df_input.loc[:, columns[0]].values\n",
    "mol_ys = df_input.loc[:, columns[1:2]].values\n",
    "atoms_ys = df_input.loc[:, columns[2:4]].values\n",
    "bonds_ys = df_input.loc[:, columns[4:6]].values\n",
    "\n",
    "atoms_ys = [\n",
    "    np.array([ast.literal_eval(atom_y) for atom_y in atom_ys], dtype=float).T\n",
    "    for atom_ys in atoms_ys\n",
    "]\n",
    "bonds_ys = [\n",
    "    np.array([ast.literal_eval(bond_y) for bond_y in bond_ys], dtype=float).T\n",
    "    for bond_ys in bonds_ys\n",
    "]\n",
    "\n",
    "df_constraints = pd.read_csv(data_dir / \"constrained_regression_constraints.csv\")\n",
    "n_mols = len(df_constraints)\n",
    "constraints_cols_to_target_cols = {\n",
    "    \"atom_target_0\": 0,\n",
    "    \"atom_target_1\": 1,\n",
    "    \"bond_target_1\": 2,\n",
    "}\n",
    "\n",
    "atom_constraint_cols = [\n",
    "    constraints_cols_to_target_cols.get(f\"atom_target_{col}\", None)\n",
    "    for col in range(atoms_ys[0].shape[1])\n",
    "]\n",
    "atom_constraints = np.hstack(\n",
    "    [\n",
    "        df_constraints.iloc[:, col].values.reshape(-1, 1)\n",
    "        if col is not None\n",
    "        else np.full((n_mols, 1), np.nan)\n",
    "        for col in atom_constraint_cols\n",
    "    ]\n",
    ")\n",
    "\n",
    "bond_constraint_cols = [\n",
    "    constraints_cols_to_target_cols.get(f\"bond_target_{col}\", None)\n",
    "    for col in range(bonds_ys[0].shape[1])\n",
    "]\n",
    "bond_constraints = np.hstack(\n",
    "    [\n",
    "        df_constraints.iloc[:, col].values.reshape(-1, 1)\n",
    "        if col is not None\n",
    "        else np.full((n_mols, 1), np.nan)\n",
    "        for col in bond_constraint_cols\n",
    "    ]\n",
    ")\n",
    "\n",
    "datapoints = [\n",
    "    data.MolAtomBondDatapoint.from_smi(\n",
    "        smi,\n",
    "        keep_h=True,\n",
    "        add_h=False,\n",
    "        reorder_atoms=True,\n",
    "        y=mol_ys[i],\n",
    "        atom_y=atoms_ys[i],\n",
    "        bond_y=bonds_ys[i],\n",
    "        atom_constraint=atom_constraints[i],\n",
    "        bond_constraint=bond_constraints[i],\n",
    "    )\n",
    "    for i, smi in enumerate(smis)\n",
    "]\n",
    "\n",
    "featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
    "\n",
    "train_dataset = data.MolAtomBondDataset(datapoints, featurizer=featurizer)\n",
    "val_dataset = data.MolAtomBondDataset(datapoints, featurizer=featurizer)\n",
    "test_dataset = data.MolAtomBondDataset(datapoints, featurizer=featurizer)\n",
    "predict_dataset = data.MolAtomBondDataset(datapoints, featurizer=featurizer)\n",
    "\n",
    "# The output scaling is automatically applied to the constraints\n",
    "atom_target_scaler = train_dataset.normalize_targets(\"atom\")\n",
    "val_dataset.normalize_targets(\"atom\", atom_target_scaler)\n",
    "atom_target_transform = nn.UnscaleTransform.from_standard_scaler(atom_target_scaler)\n",
    "\n",
    "train_dataloader = data.build_dataloader(train_dataset, shuffle=True)\n",
    "val_dataloader = data.build_dataloader(val_dataset, shuffle=False)\n",
    "test_dataloader = data.build_dataloader(test_dataset, shuffle=False)\n",
    "predict_dataloader = data.build_dataloader(predict_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cede1449",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = nn.MABBondMessagePassing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5da5beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = nn.NormAggregation()\n",
    "mol_predictor = nn.RegressionFFN(n_tasks=mol_ys.shape[1])\n",
    "atom_predictor = nn.RegressionFFN(n_tasks=atoms_ys[0].shape[1], output_transform=atom_target_transform)\n",
    "bond_predictor = nn.RegressionFFN(input_dim=(mp.output_dims[1] * 2), n_tasks=bonds_ys[0].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20acd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_constrainer = nn.ConstrainerFFN(n_constraints=(~np.isnan(atom_constraints[0])).sum())\n",
    "bond_constrainer = nn.ConstrainerFFN(n_constraints=(~np.isnan(bond_constraints[0])).sum(), fp_dim=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab1d3bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.MolAtomBondMPNN(\n",
    "    message_passing=mp,\n",
    "    agg=agg,\n",
    "    mol_predictor=mol_predictor,\n",
    "    atom_predictor=atom_predictor,\n",
    "    bond_predictor=bond_predictor,\n",
    "    atom_constrainer=atom_constrainer,\n",
    "    bond_constrainer=bond_constrainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b9f9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MolAtomBondMPNN(\n",
       "  (message_passing): MABBondMessagePassing(\n",
       "    (W_i): Linear(in_features=86, out_features=300, bias=False)\n",
       "    (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (W_vo): Linear(in_features=372, out_features=300, bias=True)\n",
       "    (W_eo): Linear(in_features=314, out_features=300, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (tau): ReLU()\n",
       "    (V_d_transform): Identity()\n",
       "    (E_d_transform): Identity()\n",
       "    (graph_transform): Identity()\n",
       "  )\n",
       "  (agg): NormAggregation()\n",
       "  (mol_predictor): RegressionFFN(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=300, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): MSE(task_weights=[[1.0]])\n",
       "    (output_transform): Identity()\n",
       "  )\n",
       "  (atom_predictor): RegressionFFN(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): MSE(task_weights=[[1.0, 1.0]])\n",
       "    (output_transform): UnscaleTransform()\n",
       "  )\n",
       "  (atom_constrainer): Constrainer(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bond_predictor): RegressionFFN(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): MSE(task_weights=[[1.0, 1.0]])\n",
       "    (output_transform): Identity()\n",
       "  )\n",
       "  (bond_constrainer): Constrainer(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=300, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bns): ModuleList(\n",
       "    (0-2): 3 x Identity()\n",
       "  )\n",
       "  (X_d_transform): Identity()\n",
       "  (metricss): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0-1): 2 x MSE(task_weights=[[1.0]])\n",
       "    )\n",
       "    (1-2): 2 x ModuleList(\n",
       "      (0): MSE(task_weights=[[1.0]])\n",
       "      (1): MSE(task_weights=[[1.0, 1.0]])\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6348d372",
   "metadata": {},
   "source": [
    "Show that the atom and bond predictions match the constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90318cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(predict_dataloader))\n",
    "bmg, V_d, E_d, X_d, *_, constraints = batch\n",
    "with torch.no_grad():\n",
    "    mol_preds, atom_preds_tensor, bond_preds_tensor = model(bmg, V_d, E_d, X_d, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef5d0a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00 -3.24249267e-08]\n",
      " [ 0.00000000e+00  3.20434570e-07]\n",
      " [ 0.00000000e+00 -1.55639648e-06]\n",
      " [ 0.00000000e+00 -1.55639648e-06]\n",
      " [ 0.00000000e+00  6.40869139e-07]\n",
      " [ 0.00000000e+00 -3.96728517e-07]\n",
      " [ 0.00000000e+00  1.28173828e-06]\n",
      " [-4.65661287e-10  1.67846680e-06]\n",
      " [ 1.86264515e-09  6.71386722e-07]\n",
      " [ 3.72529030e-09 -1.52587891e-06]\n",
      " [ 0.00000000e+00  1.31225586e-06]]\n"
     ]
    }
   ],
   "source": [
    "atoms_per_mol = [mol.GetNumAtoms() for mol in predict_dataset.mols]\n",
    "atom_preds = torch.split(atom_preds_tensor, atoms_per_mol)\n",
    "errors = predict_dataset.atom_constraints - torch.vstack([p.sum(dim=0) for p in atom_preds]).numpy()\n",
    "print(errors)\n",
    "assert np.all(np.isclose(errors[~np.isnan(errors)], 0.0, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "318dbbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[            nan  1.19209290e-07]\n",
      " [            nan  0.00000000e+00]\n",
      " [            nan  0.00000000e+00]\n",
      " [            nan  0.00000000e+00]\n",
      " [            nan  0.00000000e+00]\n",
      " [            nan  0.00000000e+00]\n",
      " [            nan  0.00000000e+00]\n",
      " [            nan  0.00000000e+00]\n",
      " [            nan  0.00000000e+00]\n",
      " [            nan  9.53674316e-07]\n",
      " [            nan -1.90734863e-06]]\n"
     ]
    }
   ],
   "source": [
    "bonds_per_mol = [mol.GetNumBonds() for mol in predict_dataset.mols]\n",
    "bond_preds = torch.split(bond_preds_tensor, bonds_per_mol)\n",
    "errors = predict_dataset.bond_constraints - torch.vstack([p.sum(dim=0) for p in bond_preds]).numpy()\n",
    "print(errors)\n",
    "assert np.all(np.isclose(errors[~np.isnan(errors)], 0.0, atol=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3051d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpointing = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-{epoch}-{val_loss:.2f}\",\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_last=True,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=False,\n",
    "    enable_checkpointing=True,\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=20,\n",
    "    callbacks=[checkpointing],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31bda413",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf checkpoints/\n",
    "! rm temp.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5f4f787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "\n",
      "  | Name             | Type                  | Params | Mode \n",
      "-------------------------------------------------------------------\n",
      "0 | message_passing  | MABBondMessagePassing | 322 K  | train\n",
      "1 | agg              | NormAggregation       | 0      | train\n",
      "2 | mol_predictor    | RegressionFFN         | 90.6 K | train\n",
      "3 | atom_predictor   | RegressionFFN         | 90.9 K | train\n",
      "4 | atom_constrainer | Constrainer           | 90.9 K | train\n",
      "5 | bond_predictor   | RegressionFFN         | 180 K  | train\n",
      "6 | bond_constrainer | Constrainer           | 180 K  | train\n",
      "7 | bns              | ModuleList            | 0      | train\n",
      "8 | X_d_transform    | Identity              | 0      | train\n",
      "9 | metricss         | ModuleList            | 0      | train\n",
      "-------------------------------------------------------------------\n",
      "956 K     Trainable params\n",
      "0         Non-trainable params\n",
      "956 K     Total params\n",
      "3.824     Total estimated model params size (MB)\n",
      "72        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00, 12.75it/s, mol_train_loss_step=0.162, atom_train_loss_step=65.60, bond_train_loss_step=7.930, train_loss_step=73.70, mol_val_loss=0.162, atom_val_loss=65.60, bond_val_loss=7.430, val_loss=73.20, mol_train_loss_epoch=0.162, atom_train_loss_epoch=65.60, bond_train_loss_epoch=7.930, train_loss_epoch=73.70]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s, mol_train_loss_step=0.162, atom_train_loss_step=65.60, bond_train_loss_step=7.930, train_loss_step=73.70, mol_val_loss=0.162, atom_val_loss=65.60, bond_val_loss=7.430, val_loss=73.20, mol_train_loss_epoch=0.162, atom_train_loss_epoch=65.60, bond_train_loss_epoch=7.930, train_loss_epoch=73.70]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d177eb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at /home/knathan/chemprop/examples/mol_atom_bond/checkpoints/best-epoch=19-val_loss=73.19.ckpt\n",
      "Loaded model weights from the checkpoint at /home/knathan/chemprop/examples/mol_atom_bond/checkpoints/best-epoch=19-val_loss=73.19.ckpt\n",
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.44it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       atom_test/mse       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    2.9788758754730225     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       bond_test/mse       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     7.432084083557129     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       mol_test/mse        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.16176404058933258    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      atom_test/mse      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   2.9788758754730225    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      bond_test/mse      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    7.432084083557129    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      mol_test/mse       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.16176404058933258   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.test(dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13ce67b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.45it/s]\n"
     ]
    }
   ],
   "source": [
    "predss = trainer.predict(model, predict_dataloader)\n",
    "mol_preds, atom_preds, bond_preds = (torch.concat(tensors) for tensors in zip(*predss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "854e213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.utils.save_model(\"temp.pt\", model)\n",
    "model = models.MolAtomBondMPNN.load_from_file(\"temp.pt\")\n",
    "with torch.no_grad():\n",
    "    mol_preds, atom_preds_tensor, bond_preds_tensor = model(bmg, V_d, E_d, X_d, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5d8fe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.MolAtomBondMPNN.load_from_checkpoint(\"checkpoints/last.ckpt\")\n",
    "with torch.no_grad():\n",
    "    mol_preds, atom_preds_tensor, bond_preds_tensor = model(bmg, V_d, E_d, X_d, constraints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
