{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Training Regression - Multicomponent"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from lightning import pytorch as pl\n",
                "from pathlib import Path\n",
                "\n",
                "from chemprop import data\n",
                "from chemprop import featurizers\n",
                "from chemprop import models\n",
                "from chemprop import nn\n",
                "from chemprop.nn import metrics\n",
                "from chemprop.models import multi\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Load data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Change your data inputs here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "chemprop_dir = Path.cwd().parent\n",
                "input_path = chemprop_dir / \"tests/data/regression/mol+mol.csv\" # path to your data .csv file containing SMILES strings and target values\n",
                "smiles_columns = ['smiles', 'solvent'] # name of the column containing SMILES strings\n",
                "target_columns = ['peakwavs_max'] # list of names of the columns containing targets"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Read data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>smiles</th>\n",
                            "      <th>solvent</th>\n",
                            "      <th>peakwavs_max</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>CCCCN1C(=O)C(=C/C=C/C=C/C=C2N(CCCC)c3ccccc3N2C...</td>\n",
                            "      <td>ClCCl</td>\n",
                            "      <td>642.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>C(=C/c1cnccn1)\\c1ccc(N(c2ccccc2)c2ccc(/C=C/c3c...</td>\n",
                            "      <td>ClCCl</td>\n",
                            "      <td>420.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>CN(C)c1ccc2c(-c3ccc(N)cc3C(=O)[O-])c3ccc(=[N+]...</td>\n",
                            "      <td>O</td>\n",
                            "      <td>544.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>c1ccc2[nH]ccc2c1</td>\n",
                            "      <td>O</td>\n",
                            "      <td>290.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>CCN(CC)c1ccc2c(c1)OC1=C(/C=C/C3=[N+](C)c4ccc5c...</td>\n",
                            "      <td>ClC(Cl)Cl</td>\n",
                            "      <td>736.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>95</th>\n",
                            "      <td>COc1ccc(C2CC(c3ccc(O)cc3)=NN2c2ccc(S(N)(=O)=O)...</td>\n",
                            "      <td>C1CCOC1</td>\n",
                            "      <td>359.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>96</th>\n",
                            "      <td>COc1ccc2c3c(c4ccc(OC)cc4c2c1)C1(c2ccccc2-c2ccc...</td>\n",
                            "      <td>C1CCCCC1</td>\n",
                            "      <td>386.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>97</th>\n",
                            "      <td>CCCCOc1c(C=C2N(C)c3ccccc3C2(C)C)c(=O)c1=O</td>\n",
                            "      <td>CCO</td>\n",
                            "      <td>425.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>98</th>\n",
                            "      <td>Cc1cc2ccc(-c3cccc4cccc(-c5ccc6cc(C)c(=O)oc6c5)...</td>\n",
                            "      <td>c1ccccc1</td>\n",
                            "      <td>324.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>99</th>\n",
                            "      <td>Cc1ccc(C(=O)c2c(C)c3ccc4cccc5c6cccc7ccc2c(c76)...</td>\n",
                            "      <td>ClCCl</td>\n",
                            "      <td>391.0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>100 rows Ã— 3 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                               smiles    solvent  peakwavs_max\n",
                            "0   CCCCN1C(=O)C(=C/C=C/C=C/C=C2N(CCCC)c3ccccc3N2C...      ClCCl         642.0\n",
                            "1   C(=C/c1cnccn1)\\c1ccc(N(c2ccccc2)c2ccc(/C=C/c3c...      ClCCl         420.0\n",
                            "2   CN(C)c1ccc2c(-c3ccc(N)cc3C(=O)[O-])c3ccc(=[N+]...          O         544.0\n",
                            "3                                    c1ccc2[nH]ccc2c1          O         290.0\n",
                            "4   CCN(CC)c1ccc2c(c1)OC1=C(/C=C/C3=[N+](C)c4ccc5c...  ClC(Cl)Cl         736.0\n",
                            "..                                                ...        ...           ...\n",
                            "95  COc1ccc(C2CC(c3ccc(O)cc3)=NN2c2ccc(S(N)(=O)=O)...    C1CCOC1         359.0\n",
                            "96  COc1ccc2c3c(c4ccc(OC)cc4c2c1)C1(c2ccccc2-c2ccc...   C1CCCCC1         386.0\n",
                            "97          CCCCOc1c(C=C2N(C)c3ccccc3C2(C)C)c(=O)c1=O        CCO         425.0\n",
                            "98  Cc1cc2ccc(-c3cccc4cccc(-c5ccc6cc(C)c(=O)oc6c5)...   c1ccccc1         324.0\n",
                            "99  Cc1ccc(C(=O)c2c(C)c3ccc4cccc5c6cccc7ccc2c(c76)...      ClCCl         391.0\n",
                            "\n",
                            "[100 rows x 3 columns]"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_input = pd.read_csv(input_path)\n",
                "df_input"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Get SMILES and targets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "smiss = df_input.loc[:, smiles_columns].values\n",
                "ys = df_input.loc[:, target_columns].values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(array([['CCCCN1C(=O)C(=C/C=C/C=C/C=C2N(CCCC)c3ccccc3N2CCCC)C(=O)N(CCCC)C1=S',\n",
                            "         'ClCCl'],\n",
                            "        ['C(=C/c1cnccn1)\\\\c1ccc(N(c2ccccc2)c2ccc(/C=C/c3cnccn3)cc2)cc1',\n",
                            "         'ClCCl'],\n",
                            "        ['CN(C)c1ccc2c(-c3ccc(N)cc3C(=O)[O-])c3ccc(=[N+](C)C)cc-3oc2c1',\n",
                            "         'O'],\n",
                            "        ['c1ccc2[nH]ccc2c1', 'O'],\n",
                            "        ['CCN(CC)c1ccc2c(c1)OC1=C(/C=C/C3=[N+](C)c4ccc5ccccc5c4C3(C)C)CCCC1=C2c1ccccc1C(=O)O',\n",
                            "         'ClC(Cl)Cl']], dtype=object),\n",
                            " array([[642.],\n",
                            "        [420.],\n",
                            "        [544.],\n",
                            "        [290.],\n",
                            "        [736.]]))"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Take a look at the first 5 SMILES strings and targets\n",
                "smiss[:5], ys[:5]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Make molecule datapoints\n",
                "Create a list of lists containing the molecule datapoints for each components. The target is stored in the 0th component."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_data = [[data.MoleculeDatapoint.from_smi(smis[0], y) for smis, y in zip(smiss, ys)]]\n",
                "all_data += [[data.MoleculeDatapoint.from_smi(smis[i]) for smis in smiss] for i in range(1, len(smiles_columns))]\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Split data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Change your data splitting inputs here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "split_key_molecule_index = 0 # key molecule used for splitting\n",
                "split = 'random' # type of split\n",
                "sizes = (0.8, 0.1, 0.1) # sizes of train, validation, and test sets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['CV_NO_VAL',\n",
                            " 'CV',\n",
                            " 'SCAFFOLD_BALANCED',\n",
                            " 'RANDOM_WITH_REPEATED_SMILES',\n",
                            " 'RANDOM',\n",
                            " 'KENNARD_STONE',\n",
                            " 'KMEANS']"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# available split types\n",
                "list(data.SplitType.keys())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Split data based on key molecule"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_data, val_data, test_data = data.split_component(all_data, split=split, sizes=sizes, key_index=split_key_molecule_index)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Get MoleculeDataset for each components"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
                "\n",
                "train_datasets = [data.MoleculeDataset(train_data[i], featurizer) for i in range(len(smiles_columns))]\n",
                "val_datasets = [data.MoleculeDataset(val_data[i], featurizer) for i in range(len(smiles_columns))]\n",
                "test_datasets = [data.MoleculeDataset(test_data[i], featurizer) for i in range(len(smiles_columns))]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Construct multicomponent dataset and scale the targets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
                        ],
                        "text/plain": [
                            "StandardScaler()"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "train_mcdset = data.MulticomponentDataset(train_datasets)\n",
                "scaler = train_mcdset.normalize_targets()\n",
                "val_mcdset = data.MulticomponentDataset(val_datasets)\n",
                "val_mcdset.normalize_targets(scaler)\n",
                "test_mcdset = data.MulticomponentDataset(test_datasets)\n",
                "test_mcdset.normalize_targets(scaler)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Construct data loader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_loader = data.MolGraphDataLoader(train_mcdset)\n",
                "val_loader = data.MolGraphDataLoader(val_mcdset, shuffle=False)\n",
                "test_loader = data.MolGraphDataLoader(test_mcdset, shuffle=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Construct multicomponent MPNN"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## MulticomponentMessagePassing\n",
                "- `blocks`: a list of message passing block used for each components\n",
                "- `n_components`: number of components"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "mcmp = nn.MulticomponentMessagePassing(\n",
                "    blocks=[nn.BondMessagePassing() for i in range(len(smiles_columns))],\n",
                "    n_components=len(smiles_columns),\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Aggregation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "agg = nn.MeanAggregation()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## RegressionFFN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "ffn = nn.RegressionFFN(\n",
                "    loc=scaler.mean_, # pass in the mean of the training targets\n",
                "    scale=scaler.scale_, # pass in the scale of the training targets\n",
                "    input_dim=mcmp.output_dim,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "metric_list = [metrics.RMSEMetric(), metrics.MAEMetric()] # Only the first metric is used for training and early stopping"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## MulticomponentMPNN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "MulticomponentMPNN(\n",
                            "  (message_passing): MulticomponentMessagePassing(\n",
                            "    (blocks): ModuleList(\n",
                            "      (0-1): 2 x BondMessagePassing(\n",
                            "        (W_i): Linear(in_features=147, out_features=300, bias=False)\n",
                            "        (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
                            "        (W_o): Linear(in_features=433, out_features=300, bias=True)\n",
                            "        (dropout): Dropout(p=0, inplace=False)\n",
                            "        (tau): ReLU()\n",
                            "      )\n",
                            "    )\n",
                            "  )\n",
                            "  (agg): MeanAggregation()\n",
                            "  (bn): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "  (predictor): RegressionFFN(\n",
                            "    (ffn): MLP(\n",
                            "      (0): Linear(in_features=600, out_features=300, bias=True)\n",
                            "      (1): ReLU()\n",
                            "      (2): Dropout(p=0, inplace=False)\n",
                            "      (3): Linear(in_features=300, out_features=1, bias=True)\n",
                            "    )\n",
                            "  )\n",
                            ")"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "mcmpnn = multi.MulticomponentMPNN(\n",
                "    mcmp,\n",
                "    agg,\n",
                "    ffn,\n",
                "    metrics=metric_list,\n",
                ")\n",
                "\n",
                "mcmpnn"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Set up trainer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/gridsan/adoner/mambaforge/envs/chemprop/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/gridsan/adoner/mambaforge/envs/chemprop/lib/py ...\n",
                        "GPU available: False, used: False\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "IPU available: False, using: 0 IPUs\n",
                        "HPU available: False, using: 0 HPUs\n"
                    ]
                }
            ],
            "source": [
                "trainer = pl.Trainer(\n",
                "    logger=False,\n",
                "    enable_checkpointing=True,\n",
                "    enable_progress_bar=True,\n",
                "    accelerator=\"auto\",\n",
                "    devices=1,\n",
                "    max_epochs=20, # number of epochs to train for\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Start training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loading `train_dataloader` to estimate number of stepping batches.\n",
                        "/home/gridsan/adoner/mambaforge/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n",
                        "\n",
                        "  | Name            | Type                         | Params\n",
                        "-----------------------------------------------------------------\n",
                        "0 | message_passing | MulticomponentMessagePassing | 528 K \n",
                        "1 | agg             | MeanAggregation              | 0     \n",
                        "2 | bn              | BatchNorm1d                  | 1.2 K \n",
                        "3 | predictor       | RegressionFFN                | 180 K \n",
                        "  | other params    | n/a                          | 1     \n",
                        "-----------------------------------------------------------------\n",
                        "710 K     Trainable params\n",
                        "1         Non-trainable params\n",
                        "710 K     Total params\n",
                        "2.842     Total estimated model params size (MB)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/gridsan/adoner/mambaforge/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  0.49it/s, train/loss=0.0605, val_loss=443.0]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  0.48it/s, train/loss=0.0605, val_loss=443.0]\n"
                    ]
                }
            ],
            "source": [
                "trainer.fit(mcmpnn, train_loader, val_loader)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Test results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/gridsan/adoner/mambaforge/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 19.80it/s]\n",
                        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                        "       Test metric             DataLoader 0\n",
                        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
                        "        test/mae            440.77487709353835\n",
                        "        test/rmse            441.3444630218094\n",
                        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                    ]
                }
            ],
            "source": [
                "results = trainer.test(mcmpnn, test_loader)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
