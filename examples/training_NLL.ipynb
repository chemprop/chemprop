{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Training with Negative Log Loss as Loss function. \n",
                "Implementation of the loss function described in [Lim et al. (2022) JCIM]('https://pubs.acs.org/doi/10.1021/acs.jcim.2c00041') for use on Poisson distributed (or negative binomial distributed) count data e.g. DNA-encoded library screening data.\n",
                "\n",
                "\n",
                "Notable differences in how this type of model is setup: \n",
                "- this loss function require two target columns, \"postive\" and \"negative\". Both must be count (int) values\n",
                "- do not use scaling, as the loss function takes the raw counts\n",
                "- do not use output transforms\n",
                "- use the softplus-based RegressionSoftplusFNN predictor to ensure positive preds\n",
                " "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/chemprop/chemprop/blob/main/examples/training.ipynb)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install chemprop from GitHub if running in Google Colab\n",
                "import os\n",
                "\n",
                "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
                "    try:\n",
                "        import chemprop\n",
                "    except ImportError:\n",
                "        !git clone https://github.com/chemprop/chemprop.git\n",
                "        %cd chemprop\n",
                "        !pip install .\n",
                "        %cd examples"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Import packages"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "from lightning import pytorch as pl\n",
                "from lightning.pytorch.callbacks import ModelCheckpoint\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "from chemprop import data, featurizers, models, nn"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Change data inputs here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "chemprop_dir = Path.cwd().parent\n",
                "input_path = chemprop_dir / \"tests\" / \"data\" / \"regression\" / \"mol\" / \"mol.csv\" # path to your data .csv file\n",
                "num_workers = 0 # number of workers for dataloader. 0 means using main process for data loading\n",
                "smiles_column = 'smiles' # name of the column containing SMILES strings\n",
                "target_columns = ['counts_pos', 'counts_neg']# list of names of the columns containing targets"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## load data -- and make some synthetic data for testing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total counts (positive samples): 602\n",
                        "Total counts (negative samples): 387\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.microsoft.datawrangler.viewer.v0+json": {
                            "columns": [
                                {
                                    "name": "index",
                                    "rawType": "int64",
                                    "type": "integer"
                                },
                                {
                                    "name": "smiles",
                                    "rawType": "object",
                                    "type": "string"
                                },
                                {
                                    "name": "lipo",
                                    "rawType": "float64",
                                    "type": "float"
                                },
                                {
                                    "name": "counts_pos",
                                    "rawType": "int64",
                                    "type": "integer"
                                },
                                {
                                    "name": "counts_neg",
                                    "rawType": "int64",
                                    "type": "integer"
                                }
                            ],
                            "ref": "88bc463e-663f-4605-a11e-387f12eca694",
                            "rows": [
                                [
                                    "0",
                                    "Cn1c(CN2CCN(CC2)c3ccc(Cl)cc3)nc4ccccc14",
                                    "3.54",
                                    "5",
                                    "6"
                                ],
                                [
                                    "1",
                                    "COc1cc(OC)c(cc1NC(=O)CSCC(=O)O)S(=O)(=O)N2C(C)CCc3ccccc23",
                                    "-1.18",
                                    "9",
                                    "2"
                                ],
                                [
                                    "2",
                                    "COC(=O)[C@@H](N1CCc2sccc2C1)c3ccccc3Cl",
                                    "3.69",
                                    "3",
                                    "3"
                                ],
                                [
                                    "3",
                                    "OC[C@H](O)CN1C(=O)C(Cc2ccccc12)NC(=O)c3cc4cc(Cl)sc4[nH]3",
                                    "3.37",
                                    "5",
                                    "5"
                                ],
                                [
                                    "4",
                                    "Cc1cccc(C[C@H](NC(=O)c2cc(nn2C)C(C)(C)C)C(=O)NCC#N)c1",
                                    "3.1",
                                    "5",
                                    "5"
                                ],
                                [
                                    "5",
                                    "OC1(CN2CCC1CC2)C#Cc3ccc(cc3)c4ccccc4",
                                    "3.14",
                                    "7",
                                    "4"
                                ],
                                [
                                    "6",
                                    "COc1cc(OC)c(cc1NC(=O)CCC(=O)O)S(=O)(=O)NCc2ccccc2N3CCCCC3",
                                    "-0.72",
                                    "6",
                                    "3"
                                ],
                                [
                                    "7",
                                    "CNc1cccc(CCOc2ccc(C[C@H](NC(=O)c3c(Cl)cccc3Cl)C(=O)O)cc2C)n1",
                                    "0.34",
                                    "5",
                                    "2"
                                ],
                                [
                                    "8",
                                    "COc1ccc(cc1)C2=COc3cc(OC)cc(OC)c3C2=O",
                                    "3.05",
                                    "3",
                                    "6"
                                ],
                                [
                                    "9",
                                    "Oc1ncnc2scc(c3ccsc3)c12",
                                    "2.25",
                                    "8",
                                    "4"
                                ],
                                [
                                    "10",
                                    "CS(=O)(=O)c1ccc(Oc2ccc(cc2)C#C[C@]3(O)CN4CCC3CC4)cc1",
                                    "1.51",
                                    "7",
                                    "1"
                                ],
                                [
                                    "11",
                                    "C[C@H](Nc1nc(Nc2cc(C)[nH]n2)c(C)nc1C#N)c3ccc(F)cn3",
                                    "2.61",
                                    "6",
                                    "2"
                                ],
                                [
                                    "12",
                                    "O=C1CCCCCN1",
                                    "-0.08",
                                    "4",
                                    "0"
                                ],
                                [
                                    "13",
                                    "CCCSc1ncccc1C(=O)N2CCCC2c3ccncc3",
                                    "1.95",
                                    "5",
                                    "3"
                                ],
                                [
                                    "14",
                                    "CC1CCCCC1NC(=O)c2cnn(c2NS(=O)(=O)c3ccc(C)cc3)c4ccccc4",
                                    "1.34",
                                    "6",
                                    "7"
                                ],
                                [
                                    "15",
                                    "Nc1ccc(cc1)c2nc3ccc(O)cc3s2",
                                    "3.2",
                                    "6",
                                    "7"
                                ],
                                [
                                    "16",
                                    "COc1ccc(cc1)N2CCN(CC2)C(=O)[C@@H]3CCCC[C@H]3C(=O)NCC#N",
                                    "1.6",
                                    "6",
                                    "3"
                                ],
                                [
                                    "17",
                                    "CCC(COC(=O)c1cc(OC)c(OC)c(OC)c1)(N(C)C)c2ccccc2",
                                    "3.77",
                                    "2",
                                    "5"
                                ],
                                [
                                    "18",
                                    "COc1cc(ccc1N2CC[C@@H](O)C2)N3N=Nc4cc(sc4C3=O)c5ccc(Cl)cc5",
                                    "3.15",
                                    "8",
                                    "3"
                                ],
                                [
                                    "19",
                                    "CO[C@H]1CN(CCN2C(=O)C=Cc3ccc(cc23)C#N)CC[C@H]1NCc4ccc5OCC(=O)Nc5n4",
                                    "0.32",
                                    "10",
                                    "3"
                                ],
                                [
                                    "20",
                                    "CC(C)(CCCCCOCCc1ccccc1)NCCc2ccc(O)c3nc(O)sc23",
                                    "2.92",
                                    "7",
                                    "5"
                                ],
                                [
                                    "21",
                                    "Clc1ccc(cc1)C(=O)Nc2oc(nn2)C(=O)Nc3ccc(cc3)N4CCOCC4",
                                    "1.92",
                                    "4",
                                    "1"
                                ],
                                [
                                    "22",
                                    "COc1ccc(Oc2cccc(CN3CCCC(C3)N4C=C(C)C(=O)NC4=O)c2)cc1",
                                    "3.17",
                                    "9",
                                    "3"
                                ],
                                [
                                    "23",
                                    "OC(=O)c1cccc(c1)N2CCC(CN3CCC(CC3)Oc4ccc(Cl)c(Cl)c4)CC2",
                                    "2.17",
                                    "4",
                                    "3"
                                ],
                                [
                                    "24",
                                    "CNCC[C@@H](Oc1ccccc1C)c2ccccc2",
                                    "1.2",
                                    "11",
                                    "4"
                                ],
                                [
                                    "25",
                                    "Clc1ccc(N2CCN(CC2)C(=O)CCCc3ccncc3)c(Cl)c1",
                                    "3.93",
                                    "4",
                                    "1"
                                ],
                                [
                                    "26",
                                    "COc1cnc(nc1N(C)C)c2ccccn2",
                                    "1.9",
                                    "7",
                                    "4"
                                ],
                                [
                                    "27",
                                    "C(CCCCNc1cc(nc2ccccc12)c3ccccc3)CCCNc4cc(nc5ccccc45)c6ccccc6",
                                    "2.27",
                                    "6",
                                    "1"
                                ],
                                [
                                    "28",
                                    "CSc1c(cnn1c2ccc(cc2)C(=O)O)C(=O)NC3C4CC5CC(CC3C5)C4",
                                    "1.2",
                                    "9",
                                    "7"
                                ],
                                [
                                    "29",
                                    "CNC1=Nc2ncccc2C(=NC1c3cccs3)c4occn4",
                                    "1.14",
                                    "4",
                                    "4"
                                ],
                                [
                                    "30",
                                    "CS(=O)(=O)C1(CC1)c2cc(nc(n2)c3cccc4[nH]ccc34)N5CC6CCC(C5)O6",
                                    "2.6",
                                    "6",
                                    "5"
                                ],
                                [
                                    "31",
                                    "CN([C@@H]1CCN(Cc2ccc(cc2)C(F)(F)F)C[C@@H]1F)C(=O)Cc3ccc(cc3)n4cnnn4",
                                    "3.3",
                                    "3",
                                    "5"
                                ],
                                [
                                    "32",
                                    "CC(=O)[C@H]1CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@]4(C)[C@H]3CC[C@]12C",
                                    "3.94",
                                    "7",
                                    "5"
                                ],
                                [
                                    "33",
                                    "CS(=O)(=O)c1ccccc1C(=O)NC[C@@H](O)CN2CCC(CC2)Oc3ccc(Cl)c(Cl)c3",
                                    "2.34",
                                    "8",
                                    "3"
                                ],
                                [
                                    "34",
                                    "O=C(NCc1ccncc1)c2ccc(Oc3ccccc3C#N)cc2",
                                    "2.57",
                                    "7",
                                    "2"
                                ],
                                [
                                    "35",
                                    "CN(C)c1ccnc2sc(C(=O)NCc3ccccc3)c(N)c12",
                                    "3.62",
                                    "8",
                                    "3"
                                ],
                                [
                                    "36",
                                    "CN1CCN(CC1)c2ccc3N=CN(C(=O)c3c2)c4cc(NC(=O)c5cscn5)ccc4C",
                                    "2.06",
                                    "9",
                                    "6"
                                ],
                                [
                                    "37",
                                    "Cn1cncc1c2c3C(=O)N(CC4CC4)C(=O)N(CC5CC5)c3nn2Cc6ccnc7ccc(Cl)cc67",
                                    "4.33",
                                    "5",
                                    "7"
                                ],
                                [
                                    "38",
                                    "COc1ccc2ncc(C#N)c(CCN3CCC(CC3)NCc4cc5SCOc5cn4)c2c1",
                                    "2.55",
                                    "11",
                                    "2"
                                ],
                                [
                                    "39",
                                    "CNC(=O)C1(CCN(CC[C@H](CN(C)C(=O)c2c(OC)c(cc3ccccc23)C#N)c4ccc(Cl)c(Cl)c4)CC1)N5CCCCC5=O",
                                    "2.78",
                                    "8",
                                    "2"
                                ],
                                [
                                    "40",
                                    "OB1N(C(=O)Nc2ccccc12)c3ccccc3",
                                    "1.4",
                                    "3",
                                    "3"
                                ],
                                [
                                    "41",
                                    "CC(C)N(CCC(C(=O)N)(c1ccccc1)c2ccccn2)C(C)C",
                                    "-0.54",
                                    "5",
                                    "6"
                                ],
                                [
                                    "42",
                                    "NC(=NC#N)c1sc(Nc2ccccc2)nc1N",
                                    "2.91",
                                    "3",
                                    "2"
                                ],
                                [
                                    "43",
                                    "CCS(=O)(=O)c1ccc(c(C)c1)c2cc(ccc2O[C@H](C)C(=O)O)C(F)(F)F",
                                    "-0.4",
                                    "4",
                                    "1"
                                ],
                                [
                                    "44",
                                    "OC(=O)COc1ccc(cc1c2cc(ccc2F)C#N)C(F)(F)F",
                                    "-0.16",
                                    "6",
                                    "3"
                                ],
                                [
                                    "45",
                                    "COc1ccc(cn1)C2=Cc3c(C)nc(N)nc3N([C@@H]4CC[C@H](CC4)OCCO)C2=O",
                                    "2.2",
                                    "5",
                                    "4"
                                ],
                                [
                                    "46",
                                    "CC(Nc1ncnc2ccccc12)c3ccccc3",
                                    "3.4",
                                    "9",
                                    "7"
                                ],
                                [
                                    "47",
                                    "CC(C)c1ccc2Oc3nc(N)c(cc3C(=O)c2c1)C(=O)O",
                                    "1.1",
                                    "6",
                                    "4"
                                ],
                                [
                                    "48",
                                    "O[C@@H](CNCCCOCCOCCc1cccc2ccccc12)c3ccc(O)c4NC(=O)Sc34",
                                    "2.28",
                                    "3",
                                    "4"
                                ],
                                [
                                    "49",
                                    "COc1ccccc1Cn2c(C)nc3ccccc23",
                                    "3.47",
                                    "8",
                                    "5"
                                ]
                            ],
                            "shape": {
                                "columns": 4,
                                "rows": 100
                            }
                        },
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>smiles</th>\n",
                            "      <th>lipo</th>\n",
                            "      <th>counts_pos</th>\n",
                            "      <th>counts_neg</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Cn1c(CN2CCN(CC2)c3ccc(Cl)cc3)nc4ccccc14</td>\n",
                            "      <td>3.54</td>\n",
                            "      <td>5</td>\n",
                            "      <td>6</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>COc1cc(OC)c(cc1NC(=O)CSCC(=O)O)S(=O)(=O)N2C(C)...</td>\n",
                            "      <td>-1.18</td>\n",
                            "      <td>9</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>COC(=O)[C@@H](N1CCc2sccc2C1)c3ccccc3Cl</td>\n",
                            "      <td>3.69</td>\n",
                            "      <td>3</td>\n",
                            "      <td>3</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>OC[C@H](O)CN1C(=O)C(Cc2ccccc12)NC(=O)c3cc4cc(C...</td>\n",
                            "      <td>3.37</td>\n",
                            "      <td>5</td>\n",
                            "      <td>5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>Cc1cccc(C[C@H](NC(=O)c2cc(nn2C)C(C)(C)C)C(=O)N...</td>\n",
                            "      <td>3.10</td>\n",
                            "      <td>5</td>\n",
                            "      <td>5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>95</th>\n",
                            "      <td>CC(C)N(CCCNC(=O)Nc1ccc(cc1)C(C)(C)C)C[C@H]2O[C...</td>\n",
                            "      <td>2.20</td>\n",
                            "      <td>8</td>\n",
                            "      <td>3</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>96</th>\n",
                            "      <td>CCN(CC)CCCCNc1ncc2CN(C(=O)N(Cc3cccc(NC(=O)C=C)...</td>\n",
                            "      <td>2.04</td>\n",
                            "      <td>3</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>97</th>\n",
                            "      <td>CCSc1c(Cc2ccccc2C(F)(F)F)sc3N(CC(C)C)C(=O)N(C)...</td>\n",
                            "      <td>4.49</td>\n",
                            "      <td>5</td>\n",
                            "      <td>6</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>98</th>\n",
                            "      <td>COc1ccc(Cc2c(N)n[nH]c2N)cc1</td>\n",
                            "      <td>0.20</td>\n",
                            "      <td>8</td>\n",
                            "      <td>6</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>99</th>\n",
                            "      <td>CCN(CCN(C)C)S(=O)(=O)c1ccc(cc1)c2cnc(N)c(n2)C(...</td>\n",
                            "      <td>2.00</td>\n",
                            "      <td>4</td>\n",
                            "      <td>3</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>100 rows Ã— 4 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                               smiles  lipo  counts_pos  \\\n",
                            "0             Cn1c(CN2CCN(CC2)c3ccc(Cl)cc3)nc4ccccc14  3.54           5   \n",
                            "1   COc1cc(OC)c(cc1NC(=O)CSCC(=O)O)S(=O)(=O)N2C(C)... -1.18           9   \n",
                            "2              COC(=O)[C@@H](N1CCc2sccc2C1)c3ccccc3Cl  3.69           3   \n",
                            "3   OC[C@H](O)CN1C(=O)C(Cc2ccccc12)NC(=O)c3cc4cc(C...  3.37           5   \n",
                            "4   Cc1cccc(C[C@H](NC(=O)c2cc(nn2C)C(C)(C)C)C(=O)N...  3.10           5   \n",
                            "..                                                ...   ...         ...   \n",
                            "95  CC(C)N(CCCNC(=O)Nc1ccc(cc1)C(C)(C)C)C[C@H]2O[C...  2.20           8   \n",
                            "96  CCN(CC)CCCCNc1ncc2CN(C(=O)N(Cc3cccc(NC(=O)C=C)...  2.04           3   \n",
                            "97  CCSc1c(Cc2ccccc2C(F)(F)F)sc3N(CC(C)C)C(=O)N(C)...  4.49           5   \n",
                            "98                        COc1ccc(Cc2c(N)n[nH]c2N)cc1  0.20           8   \n",
                            "99  CCN(CCN(C)C)S(=O)(=O)c1ccc(cc1)c2cnc(N)c(n2)C(...  2.00           4   \n",
                            "\n",
                            "    counts_neg  \n",
                            "0            6  \n",
                            "1            2  \n",
                            "2            3  \n",
                            "3            5  \n",
                            "4            5  \n",
                            "..         ...  \n",
                            "95           3  \n",
                            "96           1  \n",
                            "97           6  \n",
                            "98           6  \n",
                            "99           3  \n",
                            "\n",
                            "[100 rows x 4 columns]"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_input = pd.read_csv(input_path)\n",
                "\n",
                "\n",
                "# creating some random count data for the NLogProbEnrichment metric\n",
                "df_input['counts_pos'] = np.random.poisson(lam=6, size= df_input.shape[0])\n",
                "df_input['counts_neg'] = np.random.poisson(lam=4, size= df_input.shape[0])\n",
                "\n",
                "total_counts_pos= int(df_input['counts_pos'].sum())  # total number of positive samples\n",
                "total_counts_neg = int(df_input['counts_neg'].sum())  # total number of negative samples\n",
                "\n",
                "print(f\"Total counts (positive samples): {total_counts_pos}\")\n",
                "print(f\"Total counts (negative samples): {total_counts_neg}\")\n",
                "\n",
                "df_input"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Get SMILES and targets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "smis = df_input.loc[:, smiles_column].values\n",
                "ys = df_input.loc[:, target_columns].values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array(['Cn1c(CN2CCN(CC2)c3ccc(Cl)cc3)nc4ccccc14',\n",
                            "       'COc1cc(OC)c(cc1NC(=O)CSCC(=O)O)S(=O)(=O)N2C(C)CCc3ccccc23',\n",
                            "       'COC(=O)[C@@H](N1CCc2sccc2C1)c3ccccc3Cl',\n",
                            "       'OC[C@H](O)CN1C(=O)C(Cc2ccccc12)NC(=O)c3cc4cc(Cl)sc4[nH]3',\n",
                            "       'Cc1cccc(C[C@H](NC(=O)c2cc(nn2C)C(C)(C)C)C(=O)NCC#N)c1'],\n",
                            "      dtype=object)"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "smis[:5] # show first 5 SMILES strings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[5, 6],\n",
                            "       [9, 2],\n",
                            "       [3, 3],\n",
                            "       [5, 5],\n",
                            "       [5, 5]])"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ys[:5] # show first 5 targets"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Get molecule datapoints"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "all_data = [data.MoleculeDatapoint.from_smi(smi, y) for smi, y in zip(smis, ys)]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Perform data splitting for training, validation, and testing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "['SCAFFOLD_BALANCED',\n",
                            " 'RANDOM_WITH_REPEATED_SMILES',\n",
                            " 'RANDOM',\n",
                            " 'KENNARD_STONE',\n",
                            " 'KMEANS']"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# available split types\n",
                "list(data.SplitType.keys())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Chemprop's `make_split_indices` function will always return a two- (if no validation) or three-length tuple.\n",
                "Each member is a list of length `num_replicates`.\n",
                "The inner lists then contain the actual indices for splitting.\n",
                "\n",
                "The type signature for this return type is `tuple[list[list[int]], ...]`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "The return type of make_split_indices has changed in v2.1 - see help(make_split_indices)\n"
                    ]
                }
            ],
            "source": [
                "mols = [d.mol for d in all_data]  # RDkit Mol objects are use for structure based splits\n",
                "train_indices, val_indices, test_indices = data.make_split_indices(mols, \"random\", (0.8, 0.1, 0.1))  # unpack the tuple into three separate lists\n",
                "train_data, val_data, test_data = data.split_data_by_indices(\n",
                "    all_data, train_indices, val_indices, test_indices\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Chemprop's splitting function implements our preferred method of data splitting, which is random replication.\n",
                "It's also possible to add your own custom cross-validation splitter, such as one of those as implemented in scikit-learn, as long as you get the data into the same `tuple[list[list[int]], ...]` data format with something like this:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import KFold\n",
                "\n",
                "k_splits = KFold(n_splits=5)\n",
                "k_train_indices, k_val_indices, k_test_indices = [], [], []\n",
                "for fold in k_splits.split(mols):\n",
                "    k_train_indices.append(fold[0])\n",
                "    k_val_indices.append([])\n",
                "    k_test_indices.append(fold[1])\n",
                "k_train_data, _, k_test_data = data.split_data_by_indices(\n",
                "    all_data, k_train_indices, None, k_test_indices\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Get MoleculeDataset\n",
                "Recall that the data is in a list equal in length to the number of replicates, so we select the zero index of the list to get the first replicate."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "featurizer = featurizers.SimpleMoleculeMolGraphFeaturizer()\n",
                "\n",
                "train_dset = data.MoleculeDataset(train_data[0], featurizer)\n",
                "\n",
                "#! NO scaler - loss function takes the raw counts as input\n",
                "#scaler = train_dset.normalize_targets()\n",
                "\n",
                "val_dset = data.MoleculeDataset(val_data[0], featurizer)\n",
                "#val_dset.normalize_targets(scaler)\n",
                "\n",
                "test_dset = data.MoleculeDataset(test_data[0], featurizer)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Get DataLoader"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_loader = data.build_dataloader(train_dset, num_workers=num_workers)\n",
                "val_loader = data.build_dataloader(val_dset, num_workers=num_workers, shuffle=False)\n",
                "test_loader = data.build_dataloader(test_dset, num_workers=num_workers, shuffle=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Change Message-Passing Neural Network (MPNN) inputs here"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Message Passing\n",
                "A `Message passing` constructs molecular graphs using message passing to learn node-level hidden representations.\n",
                "\n",
                "Options are `mp = nn.BondMessagePassing()` or `mp = nn.AtomMessagePassing()`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "mp = nn.BondMessagePassing()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Aggregation\n",
                "An `Aggregation` is responsible for constructing a graph-level representation from the set of node-level representations after message passing.\n",
                "\n",
                "Available options can be found in ` nn.agg.AggregationRegistry`, including\n",
                "- `agg = nn.MeanAggregation()`\n",
                "- `agg = nn.SumAggregation()`\n",
                "- `agg = nn.NormAggregation()`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "agg = nn.MeanAggregation()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Feed-Forward Network (FFN)\n",
                "\n",
                "A `FFN` takes the aggregated representations and make target predictions.\n",
                "\n",
                "Available options can be found in `nn.PredictorRegistry`.\n",
                "\n",
                "For regression:\n",
                "- `ffn = nn.RegressionFFN()`\n",
                "- `ffn = nn.MveFFN()`\n",
                "- `ffn = nn.EvidentialFFN()`\n",
                "\n",
                "For classification:\n",
                "- `ffn = nn.BinaryClassificationFFN()`\n",
                "- `ffn = nn.BinaryDirichletFFN()`\n",
                "- `ffn = nn.MulticlassClassificationFFN()`\n",
                "- `ffn = nn.MulticlassDirichletFFN()`\n",
                "\n",
                "For spectral:\n",
                "- `ffn = nn.SpectralFFN()` # will be available in future version"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ClassRegistry {\n",
                        "    'regression': <class 'chemprop.nn.predictors.RegressionFFN'>,\n",
                        "    'regression-mve': <class 'chemprop.nn.predictors.MveFFN'>,\n",
                        "    'regression-evidential': <class 'chemprop.nn.predictors.EvidentialFFN'>,\n",
                        "    'regression-quantile': <class 'chemprop.nn.predictors.QuantileFFN'>,\n",
                        "    'classification': <class 'chemprop.nn.predictors.BinaryClassificationFFN'>,\n",
                        "    'classification-dirichlet': <class 'chemprop.nn.predictors.BinaryDirichletFFN'>,\n",
                        "    'multiclass': <class 'chemprop.nn.predictors.MulticlassClassificationFFN'>,\n",
                        "    'multiclass-dirichlet': <class 'chemprop.nn.predictors.MulticlassDirichletFFN'>,\n",
                        "    'spectral': <class 'chemprop.nn.predictors.SpectralFFN'>,\n",
                        "    'regression_softplus': <class 'chemprop.nn.predictors.RegressionSoftplusFFN'>\n",
                        "}\n"
                    ]
                }
            ],
            "source": [
                "print(nn.PredictorRegistry)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "#output_transform = nn.UnscaleTransform.from_standard_scaler(scaler)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "ffn = nn.predictors.RegressionSoftplusFFN(criterion=nn.metrics.NLogProbEnrichment(n1 = total_counts_pos,\n",
                "                                                                         n2 = total_counts_neg,\n",
                "                                                                         method=\"sqrt\", \n",
                "                                                                         zscale=1.0,\n",
                "                                                                         ))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Batch Norm\n",
                "A `Batch Norm` normalizes the outputs of the aggregation by re-centering and re-scaling.\n",
                "\n",
                "Whether to use batch norm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "batch_norm = True"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Metrics\n",
                "`Metrics` are the ways to evaluate the performance of model predictions.\n",
                "\n",
                "Available options can be found in `metrics.MetricRegistry`, including"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ClassRegistry {\n",
                        "    'mse': <class 'chemprop.nn.metrics.MSE'>,\n",
                        "    'mae': <class 'chemprop.nn.metrics.MAE'>,\n",
                        "    'rmse': <class 'chemprop.nn.metrics.RMSE'>,\n",
                        "    'bounded-mse': <class 'chemprop.nn.metrics.BoundedMSE'>,\n",
                        "    'bounded-mae': <class 'chemprop.nn.metrics.BoundedMAE'>,\n",
                        "    'bounded-rmse': <class 'chemprop.nn.metrics.BoundedRMSE'>,\n",
                        "    'r2': <class 'chemprop.nn.metrics.R2Score'>,\n",
                        "    'binary-mcc': <class 'chemprop.nn.metrics.BinaryMCCMetric'>,\n",
                        "    'multiclass-mcc': <class 'chemprop.nn.metrics.MulticlassMCCMetric'>,\n",
                        "    'roc': <class 'chemprop.nn.metrics.BinaryAUROC'>,\n",
                        "    'prc': <class 'chemprop.nn.metrics.BinaryAUPRC'>,\n",
                        "    'accuracy': <class 'chemprop.nn.metrics.BinaryAccuracy'>,\n",
                        "    'f1': <class 'chemprop.nn.metrics.BinaryF1Score'>\n",
                        "}\n"
                    ]
                }
            ],
            "source": [
                "print(nn.metrics.MetricRegistry)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "metric_list = [nn.metrics.NLogProbEnrichment(n1=total_counts_pos, n2=total_counts_neg)] # Only the first metric is used for training and early stopping"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Constructs MPNN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "MPNN(\n",
                            "  (message_passing): BondMessagePassing(\n",
                            "    (W_i): Linear(in_features=86, out_features=300, bias=False)\n",
                            "    (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
                            "    (W_o): Linear(in_features=372, out_features=300, bias=True)\n",
                            "    (dropout): Dropout(p=0.0, inplace=False)\n",
                            "    (tau): ReLU()\n",
                            "    (V_d_transform): Identity()\n",
                            "    (graph_transform): Identity()\n",
                            "  )\n",
                            "  (agg): MeanAggregation()\n",
                            "  (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "  (predictor): RegressionSoftplusFFN(\n",
                            "    (ffn): MLP(\n",
                            "      (0): Sequential(\n",
                            "        (0): Linear(in_features=300, out_features=300, bias=True)\n",
                            "      )\n",
                            "      (1): Sequential(\n",
                            "        (0): ReLU()\n",
                            "        (1): Dropout(p=0.0, inplace=False)\n",
                            "        (2): Linear(in_features=300, out_features=1, bias=True)\n",
                            "      )\n",
                            "    )\n",
                            "    (criterion): NLogProbEnrichment(n1=602, n2=387, method='sqrt', zscale=1.0)\n",
                            "    (output_transform): Identity()\n",
                            "  )\n",
                            "  (X_d_transform): Identity()\n",
                            "  (metrics): ModuleList(\n",
                            "    (0-1): 2 x NLogProbEnrichment(n1=602, n2=387, method='sqrt', zscale=1.0)\n",
                            "  )\n",
                            ")"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "mpnn = models.MPNN(mp, agg, ffn, batch_norm, metric_list)\n",
                "mpnn"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Set up trainer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "GPU available: True (cuda), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "HPU available: False, using: 0 HPUs\n"
                    ]
                }
            ],
            "source": [
                "# Configure model checkpointing\n",
                "checkpointing = ModelCheckpoint(\n",
                "    \"checkpoints\",  # Directory where model checkpoints will be saved\n",
                "    \"best-{epoch}-{val_loss:.2f}\",  # Filename format for checkpoints, including epoch and validation loss\n",
                "    \"val_loss\",  # Metric used to select the best checkpoint (based on validation loss)\n",
                "    mode=\"min\",  # Save the checkpoint with the lowest validation loss (minimization objective)\n",
                "    save_last=True,  # Always save the most recent checkpoint, even if it's not the best\n",
                ")\n",
                "\n",
                "\n",
                "trainer = pl.Trainer(\n",
                "    logger=False,\n",
                "    enable_checkpointing=True, # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
                "    enable_progress_bar=True,\n",
                "    #gradient_clip_val=1.0,\n",
                "    accelerator=\"auto\",\n",
                "    devices=1,\n",
                "    max_epochs=20, # number of epochs to train for\n",
                "    callbacks=[checkpointing], # Use the configured checkpoint callback\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Start training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
                        "Loading `train_dataloader` to estimate number of stepping batches.\n",
                        "\n",
                        "  | Name            | Type                  | Params | Mode \n",
                        "------------------------------------------------------------------\n",
                        "0 | message_passing | BondMessagePassing    | 227 K  | train\n",
                        "1 | agg             | MeanAggregation       | 0      | train\n",
                        "2 | bn              | BatchNorm1d           | 600    | train\n",
                        "3 | predictor       | RegressionSoftplusFFN | 90.6 K | train\n",
                        "4 | X_d_transform   | Identity              | 0      | train\n",
                        "5 | metrics         | ModuleList            | 0      | train\n",
                        "------------------------------------------------------------------\n",
                        "318 K     Trainable params\n",
                        "0         Non-trainable params\n",
                        "318 K     Total params\n",
                        "1.276     Total estimated model params size (MB)\n",
                        "24        Modules in train mode\n",
                        "0         Modules in eval mode\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]R: tensor([0.8934, 0.7801, 0.7100, 0.8309, 0.8018, 0.8434, 1.0564, 0.7718, 0.7418,\n",
                        "        0.8346], device='cuda:0')\n",
                        "R: tensor([0.8934, 0.7801, 0.7100, 0.8309, 0.8018, 0.8434, 1.0564, 0.7718, 0.7418,\n",
                        "        0.8346], device='cuda:0')\n",
                        "Epoch 0:   0%|          | 0/2 [00:00<?, ?it/s]                             R: tensor([0.2873, 0.7095, 0.5595, 0.9451, 1.0714, 0.8623, 1.0195, 0.9147, 0.9225,\n",
                        "        0.4072, 0.8606, 0.4217, 0.6482, 0.6236, 0.3913, 1.1838, 1.3800, 0.9403,\n",
                        "        0.8759, 0.6890, 1.0235, 0.8032, 1.0168, 1.3530, 0.8492, 1.2028, 1.4166,\n",
                        "        0.4565, 1.7816, 1.2263, 0.9669, 0.7258, 1.0388, 1.6447, 1.5602, 1.1928,\n",
                        "        0.9170, 1.6732, 1.1278, 1.5351, 0.6177, 1.4999, 1.0432, 0.5590, 0.6943,\n",
                        "        1.5709, 1.2063, 0.5056, 1.2279, 0.7503, 0.8883, 0.7098, 2.2506, 0.5794,\n",
                        "        1.4985, 1.9135, 2.6537, 0.5651, 2.2482, 0.8112, 0.5612, 1.7580, 1.0539,\n",
                        "        0.5451], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 11.35it/s, train_loss_step=0.191]R: tensor([0.6137, 1.1111, 1.6436, 1.2165, 2.7313, 0.9134, 0.8606, 1.3501, 1.1606,\n",
                        "        0.5261, 0.6507, 0.9016, 2.4768, 1.6007, 1.3959, 0.2395],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 16.27it/s, train_loss_step=0.657]R: tensor([0.8337, 0.7460, 0.7333, 0.8126, 0.7887, 0.8305, 1.0669, 0.7466, 0.7358,\n",
                        "        0.8416], device='cuda:0')\n",
                        "R: tensor([0.8337, 0.7460, 0.7333, 0.8126, 0.7887, 0.8305, 1.0669, 0.7466, 0.7358,\n",
                        "        0.8416], device='cuda:0')\n",
                        "Epoch 1:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.657, val_loss=1.590, train_loss_epoch=0.285]        R: tensor([0.7165, 1.1558, 0.5636, 0.7292, 2.4186, 0.2543, 1.0189, 0.5923, 0.7898,\n",
                        "        0.7353, 2.0645, 1.9825, 1.7399, 0.5658, 1.2338, 0.6313, 1.6701, 0.9353,\n",
                        "        0.5932, 1.3897, 0.3064, 0.5233, 1.1730, 1.2999, 0.6187, 0.7000, 1.5155,\n",
                        "        0.5231, 1.0514, 1.0517, 2.8659, 0.4170, 0.5195, 1.4995, 0.5525, 1.0926,\n",
                        "        0.8214, 0.9652, 1.8635, 1.0478, 1.2358, 0.8684, 0.4862, 0.4264, 2.1353,\n",
                        "        1.6551, 1.0493, 1.3931, 1.6117, 0.6631, 1.3373, 2.0964, 0.7062, 0.9005,\n",
                        "        0.8085, 0.6759, 1.9674, 0.5906, 0.6630, 0.8005, 1.0310, 0.6023, 1.3471,\n",
                        "        2.3706], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 12.31it/s, train_loss_step=0.224, val_loss=1.590, train_loss_epoch=0.285]R: tensor([0.6237, 1.4536, 0.4159, 0.8302, 1.4849, 1.2133, 0.9012, 0.9197, 1.0743,\n",
                        "        1.3683, 1.0298, 0.6500, 0.4458, 2.0921, 1.1036, 1.0882],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 18.30it/s, train_loss_step=0.456, val_loss=1.590, train_loss_epoch=0.285]R: tensor([0.8531, 0.7369, 0.6832, 0.8003, 0.7606, 0.8069, 1.1466, 0.7377, 0.7211,\n",
                        "        0.8160], device='cuda:0')\n",
                        "R: tensor([0.8531, 0.7369, 0.6832, 0.8003, 0.7606, 0.8069, 1.1466, 0.7377, 0.7211,\n",
                        "        0.8160], device='cuda:0')\n",
                        "Epoch 2:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.456, val_loss=1.620, train_loss_epoch=0.270]        R: tensor([0.6488, 1.4267, 3.1214, 1.1577, 1.2738, 0.5439, 0.7669, 0.7870, 0.8047,\n",
                        "        0.5865, 0.6845, 0.6479, 1.1171, 0.3025, 1.7172, 1.1448, 0.8370, 1.4752,\n",
                        "        0.5553, 0.3651, 1.8092, 0.6651, 1.9378, 1.3492, 0.7662, 0.4996, 0.6799,\n",
                        "        1.2525, 0.8953, 2.0317, 2.4182, 0.9119, 1.6073, 1.3427, 1.0928, 0.9714,\n",
                        "        1.3993, 0.9222, 2.5733, 1.4530, 0.9838, 0.5311, 1.5859, 0.4872, 1.0123,\n",
                        "        0.6024, 0.4567, 1.2165, 0.6165, 0.9893, 0.9118, 2.1690, 1.1002, 0.6052,\n",
                        "        1.5939, 1.6835, 2.2945, 0.5705, 1.5200, 0.9500, 0.8253, 1.2444, 0.7179,\n",
                        "        0.7893], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 11.83it/s, train_loss_step=0.287, val_loss=1.620, train_loss_epoch=0.270]R: tensor([0.7088, 1.2239, 0.9204, 1.0747, 0.5073, 1.2995, 1.0926, 0.9497, 1.4508,\n",
                        "        1.2833, 1.2274, 0.8934, 1.3322, 1.3384, 0.5490, 1.0219],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 18.25it/s, train_loss_step=0.671, val_loss=1.620, train_loss_epoch=0.270]R: tensor([0.8202, 0.7445, 0.6559, 0.7504, 0.7518, 0.7736, 1.1451, 0.7211, 0.6954,\n",
                        "        0.7896], device='cuda:0')\n",
                        "R: tensor([0.8202, 0.7445, 0.6559, 0.7504, 0.7518, 0.7736, 1.1451, 0.7211, 0.6954,\n",
                        "        0.7896], device='cuda:0')\n",
                        "Epoch 3:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.671, val_loss=1.640, train_loss_epoch=0.364]        R: tensor([0.9012, 1.7209, 0.7294, 0.6619, 0.7434, 1.5843, 1.8740, 0.3250, 1.0048,\n",
                        "        0.7946, 1.6483, 1.4551, 0.7874, 1.1523, 0.7244, 0.7439, 0.6244, 1.7913,\n",
                        "        1.2080, 0.7576, 0.4807, 1.0913, 0.8700, 0.6022, 0.5601, 0.6045, 1.2964,\n",
                        "        2.2953, 1.5501, 0.7288, 0.9340, 0.3196, 1.5633, 0.3589, 1.0514, 0.5768,\n",
                        "        1.5588, 0.6690, 0.7626, 0.6718, 0.6712, 0.8665, 1.2920, 2.0182, 1.1935,\n",
                        "        0.9289, 1.4613, 1.0604, 1.7504, 0.3090, 1.7027, 0.5348, 1.2103, 1.1168,\n",
                        "        0.6967, 0.5535, 0.9082, 1.1663, 1.2717, 1.5978, 1.4267, 0.7508, 0.7824,\n",
                        "        2.6241], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 11.87it/s, train_loss_step=0.354, val_loss=1.640, train_loss_epoch=0.364]R: tensor([0.8693, 0.4194, 0.7574, 0.2436, 1.0216, 1.2504, 1.0656, 1.6095, 0.4966,\n",
                        "        0.8235, 1.2371, 1.0632, 2.0107, 0.8493, 2.7424, 0.6884],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 17.91it/s, train_loss_step=0.442, val_loss=1.640, train_loss_epoch=0.364]R: tensor([0.7786, 0.6782, 0.6595, 0.7844, 0.7114, 0.8601, 1.5325, 0.6189, 0.7309,\n",
                        "        0.8303], device='cuda:0')\n",
                        "R: tensor([0.7786, 0.6782, 0.6595, 0.7844, 0.7114, 0.8601, 1.5325, 0.6189, 0.7309,\n",
                        "        0.8303], device='cuda:0')\n",
                        "Epoch 4:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.442, val_loss=1.560, train_loss_epoch=0.371]        R: tensor([2.0849, 0.6887, 0.6946, 0.6161, 1.5455, 0.7580, 0.6269, 0.6324, 1.8352,\n",
                        "        1.7692, 0.2949, 1.3717, 0.6452, 1.7904, 0.5845, 1.5097, 1.2235, 0.8207,\n",
                        "        0.8345, 1.2223, 1.3698, 1.3705, 0.6810, 1.5588, 1.2381, 2.0920, 0.9331,\n",
                        "        2.7563, 1.5761, 1.2019, 0.9138, 0.8392, 0.7764, 0.6855, 1.6838, 0.9775,\n",
                        "        2.6103, 1.7835, 0.3264, 0.6097, 0.8947, 1.0423, 0.9700, 0.6711, 0.5722,\n",
                        "        1.4927, 1.0142, 2.6689, 0.7520, 0.9148, 0.7792, 1.2352, 0.3660, 0.8798,\n",
                        "        1.2236, 0.8055, 2.0238, 0.5223, 0.5582, 0.4974, 0.9459, 1.9576, 0.5404,\n",
                        "        2.2020], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 15.36it/s, train_loss_step=0.457, val_loss=1.560, train_loss_epoch=0.371]R: tensor([1.2758, 2.0714, 2.5678, 1.0253, 0.6408, 1.2561, 1.2171, 0.4721, 0.4671,\n",
                        "        0.8918, 1.2532, 0.6558, 1.7159, 0.6823, 0.4438, 1.2357],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 21.72it/s, train_loss_step=0.258, val_loss=1.560, train_loss_epoch=0.371]R: tensor([0.9347, 0.8722, 0.8235, 0.8455, 0.8811, 0.9245, 1.5493, 0.7919, 0.7824,\n",
                        "        0.9047], device='cuda:0')\n",
                        "R: tensor([0.9347, 0.8722, 0.8235, 0.8455, 0.8811, 0.9245, 1.5493, 0.7919, 0.7824,\n",
                        "        0.9047], device='cuda:0')\n",
                        "Epoch 5:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.258, val_loss=1.430, train_loss_epoch=0.417]        R: tensor([0.6943, 0.9186, 0.3869, 0.7602, 1.1171, 1.7741, 0.7384, 1.6373, 1.7201,\n",
                        "        1.4181, 0.8142, 0.3421, 0.9905, 0.8595, 0.9438, 2.2086, 1.5291, 0.4650,\n",
                        "        0.6212, 0.9149, 1.2418, 0.5752, 0.6745, 1.4265, 0.5583, 2.4480, 1.6152,\n",
                        "        1.5469, 1.7430, 2.0265, 0.9649, 1.8954, 1.1787, 2.0280, 0.9646, 0.8230,\n",
                        "        0.9335, 1.0951, 1.0458, 0.8832, 2.4902, 1.2631, 1.0117, 1.3337, 1.3749,\n",
                        "        0.6090, 0.5865, 2.7275, 1.1973, 1.4545, 0.9335, 0.6177, 1.0759, 0.7691,\n",
                        "        1.8105, 1.6499, 1.4117, 1.0993, 1.8706, 0.6566, 0.6818, 0.8522, 0.7701,\n",
                        "        0.4415], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 14.72it/s, train_loss_step=0.372, val_loss=1.430, train_loss_epoch=0.417]R: tensor([1.1772, 0.5435, 1.3093, 1.0312, 1.0469, 0.8443, 1.6580, 0.9956, 0.2998,\n",
                        "        1.2492, 1.6356, 0.8579, 1.1062, 0.4783, 1.1147, 0.9355],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 21.60it/s, train_loss_step=0.510, val_loss=1.430, train_loss_epoch=0.417]R: tensor([0.9752, 1.0018, 0.8188, 0.8817, 0.9915, 0.9236, 1.4357, 0.9056, 0.7999,\n",
                        "        0.9359], device='cuda:0')\n",
                        "R: tensor([0.9752, 1.0018, 0.8188, 0.8817, 0.9915, 0.9236, 1.4357, 0.9056, 0.7999,\n",
                        "        0.9359], device='cuda:0')\n",
                        "Epoch 6:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.510, val_loss=1.410, train_loss_epoch=0.399]        R: tensor([1.1878, 1.8953, 0.4719, 0.8564, 0.7901, 0.8418, 1.4296, 1.3515, 0.7922,\n",
                        "        0.8723, 1.4418, 0.7521, 0.7706, 1.0320, 0.6584, 2.7346, 0.8863, 0.8339,\n",
                        "        1.6981, 1.1667, 1.4191, 1.1277, 0.7453, 1.5300, 0.6823, 0.6693, 0.4043,\n",
                        "        0.8572, 1.1798, 2.2154, 0.9693, 1.1320, 1.4727, 0.7992, 0.9491, 0.8830,\n",
                        "        0.6087, 1.1599, 0.9886, 0.6311, 0.9303, 1.0492, 0.7805, 0.5671, 1.4813,\n",
                        "        1.3370, 0.6242, 1.6133, 0.3386, 1.6516, 1.1607, 0.4602, 0.5074, 1.8215,\n",
                        "        0.7846, 1.3830, 0.8653, 0.8203, 1.9554, 1.6889, 0.7985, 0.8015, 0.2310,\n",
                        "        0.4233], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 13.19it/s, train_loss_step=0.348, val_loss=1.410, train_loss_epoch=0.399]R: tensor([0.9364, 0.4701, 2.4037, 0.5184, 0.9856, 0.7786, 0.9371, 0.6903, 1.0086,\n",
                        "        1.2852, 2.0389, 1.1141, 1.4121, 1.8035, 1.0403, 0.6600],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 19.49it/s, train_loss_step=0.522, val_loss=1.410, train_loss_epoch=0.399]R: tensor([0.9323, 0.9775, 0.7352, 0.9147, 0.9959, 0.9450, 1.5142, 0.8805, 0.8474,\n",
                        "        0.9887], device='cuda:0')\n",
                        "R: tensor([0.9323, 0.9775, 0.7352, 0.9147, 0.9959, 0.9450, 1.5142, 0.8805, 0.8474,\n",
                        "        0.9887], device='cuda:0')\n",
                        "Epoch 7:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.522, val_loss=1.390, train_loss_epoch=0.383]        R: tensor([0.7050, 0.6562, 0.6466, 0.4784, 0.5318, 0.8720, 0.8382, 0.8203, 1.4871,\n",
                        "        0.6711, 0.6586, 0.7485, 1.4089, 0.9990, 1.4305, 1.0498, 0.9023, 1.5578,\n",
                        "        1.3172, 1.4061, 1.3521, 0.8558, 1.0133, 0.2516, 1.5651, 0.8872, 0.7125,\n",
                        "        2.7019, 1.7101, 0.9029, 0.5900, 0.5608, 1.9331, 0.9407, 1.2608, 0.7473,\n",
                        "        1.2921, 0.7401, 1.6332, 0.7637, 0.4032, 0.8442, 0.4710, 0.9257, 0.7460,\n",
                        "        1.2391, 1.0471, 0.7416, 0.9094, 0.9546, 1.0610, 0.9034, 1.5525, 0.6305,\n",
                        "        0.6297, 0.5633, 1.9545, 1.0126, 0.6776, 0.9492, 0.6246, 0.5388, 1.2087,\n",
                        "        2.3847], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 15.80it/s, train_loss_step=0.311, val_loss=1.390, train_loss_epoch=0.383]R: tensor([2.0601, 0.5484, 0.3055, 0.5336, 1.4672, 1.1617, 1.9663, 0.3563, 1.0739,\n",
                        "        1.9395, 1.2397, 0.3337, 1.0323, 2.0297, 1.2557, 0.8692],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 21.99it/s, train_loss_step=0.308, val_loss=1.390, train_loss_epoch=0.383]R: tensor([0.9791, 0.9515, 0.8061, 0.9498, 0.9943, 1.0236, 1.6320, 0.8885, 0.9002,\n",
                        "        1.0544], device='cuda:0')\n",
                        "R: tensor([0.9791, 0.9515, 0.8061, 0.9498, 0.9943, 1.0236, 1.6320, 0.8885, 0.9002,\n",
                        "        1.0544], device='cuda:0')\n",
                        "Epoch 8:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.308, val_loss=1.370, train_loss_epoch=0.311]        R: tensor([0.9283, 0.9762, 1.0581, 1.0586, 1.5845, 1.2839, 1.4404, 2.8198, 1.3529,\n",
                        "        0.7064, 1.1224, 1.6693, 0.2616, 0.6609, 1.4970, 0.8285, 0.5873, 0.6075,\n",
                        "        1.2949, 1.1320, 0.7954, 1.7309, 0.4600, 0.8082, 0.9824, 2.2327, 1.3397,\n",
                        "        0.8861, 1.2246, 2.2496, 0.4340, 1.6567, 0.8392, 0.7394, 0.8087, 0.7263,\n",
                        "        0.4435, 1.5779, 1.4843, 0.6532, 1.8231, 0.8944, 0.7919, 1.5667, 1.5926,\n",
                        "        1.2388, 1.6486, 0.7319, 0.9404, 2.5540, 0.6976, 2.3359, 0.6125, 0.6220,\n",
                        "        0.5418, 0.8339, 0.6957, 0.8612, 0.4473, 0.7193, 0.6326, 2.5193, 0.5878,\n",
                        "        1.2623], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 14.57it/s, train_loss_step=0.262, val_loss=1.370, train_loss_epoch=0.311]R: tensor([0.3722, 0.8349, 0.7701, 1.0779, 1.2462, 1.6168, 0.6879, 1.0773, 0.6298,\n",
                        "        0.8966, 1.6713, 0.8996, 1.0345, 1.4831, 0.7004, 1.2046],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 21.28it/s, train_loss_step=0.222, val_loss=1.370, train_loss_epoch=0.311]R: tensor([1.0797, 0.9080, 0.8565, 0.9721, 0.9824, 1.0781, 1.7364, 0.9171, 0.9163,\n",
                        "        1.0780], device='cuda:0')\n",
                        "R: tensor([1.0797, 0.9080, 0.8565, 0.9721, 0.9824, 1.0781, 1.7364, 0.9171, 0.9163,\n",
                        "        1.0780], device='cuda:0')\n",
                        "Epoch 9:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.222, val_loss=1.420, train_loss_epoch=0.254]        R: tensor([1.3494, 1.5020, 0.8548, 1.6823, 0.3804, 0.4771, 0.8955, 0.7252, 0.7693,\n",
                        "        0.9474, 0.8281, 2.2643, 0.6748, 0.6885, 0.8231, 1.4334, 1.0491, 0.8889,\n",
                        "        0.6222, 0.8636, 0.8826, 2.1628, 1.2521, 2.6280, 0.9689, 0.6447, 0.9655,\n",
                        "        1.4594, 0.4687, 0.9287, 1.7026, 0.6631, 1.2789, 1.5367, 1.2925, 1.8692,\n",
                        "        2.3572, 1.6814, 1.6535, 0.8737, 1.7655, 1.3098, 1.1288, 0.9672, 2.2144,\n",
                        "        1.6308, 1.3724, 0.4437, 0.8056, 0.2842, 1.0634, 0.7066, 0.8519, 1.3971,\n",
                        "        1.0655, 1.4591, 0.6787, 2.4362, 0.5985, 0.4713, 0.6601, 0.6737, 0.6692,\n",
                        "        0.9816], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 9:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 13.29it/s, train_loss_step=0.246, val_loss=1.420, train_loss_epoch=0.254]R: tensor([1.5384, 0.9083, 0.7801, 0.8944, 1.0693, 1.4008, 1.0941, 1.2381, 0.6269,\n",
                        "        0.7040, 0.7638, 1.0479, 0.6929, 1.6941, 2.3260, 2.3448],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 18.30it/s, train_loss_step=0.523, val_loss=1.420, train_loss_epoch=0.254]R: tensor([1.1784, 0.8762, 0.8660, 0.9716, 0.9903, 1.0875, 1.7452, 0.9556, 0.8868,\n",
                        "        1.0683], device='cuda:0')\n",
                        "R: tensor([1.1784, 0.8762, 0.8660, 0.9716, 0.9903, 1.0875, 1.7452, 0.9556, 0.8868,\n",
                        "        1.0683], device='cuda:0')\n",
                        "Epoch 10:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.523, val_loss=1.470, train_loss_epoch=0.301]       R: tensor([2.3533, 1.3844, 1.5591, 1.4115, 1.6805, 1.5578, 0.6585, 0.6442, 2.2332,\n",
                        "        1.0598, 2.8696, 0.5635, 0.8497, 0.6247, 1.3498, 1.6899, 1.6372, 1.2098,\n",
                        "        0.8601, 1.0522, 0.3067, 0.8519, 1.2899, 1.1140, 0.7712, 0.6122, 1.9846,\n",
                        "        0.8533, 0.8062, 0.6099, 1.0416, 0.9545, 1.0976, 0.4767, 0.8253, 0.7997,\n",
                        "        0.8466, 0.8485, 2.5394, 0.5725, 0.8896, 1.5803, 0.8318, 0.3879, 0.7461,\n",
                        "        2.3038, 1.0578, 1.3647, 1.5588, 0.6519, 1.6529, 0.5603, 0.8808, 0.9948,\n",
                        "        0.9589, 0.9957, 2.1610, 0.9352, 1.7409, 1.3033, 0.7039, 0.5947, 1.0152,\n",
                        "        0.4758], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 13.67it/s, train_loss_step=0.244, val_loss=1.470, train_loss_epoch=0.301]R: tensor([0.9266, 2.6198, 0.8248, 1.8198, 0.7174, 1.6718, 1.8029, 3.1596, 1.4185,\n",
                        "        0.5700, 0.2201, 0.8527, 0.4999, 1.4968, 1.3188, 0.8672],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 20.07it/s, train_loss_step=0.254, val_loss=1.470, train_loss_epoch=0.301]R: tensor([1.2639, 0.8811, 0.8410, 0.9465, 1.0097, 1.0425, 1.6608, 0.9957, 0.8190,\n",
                        "        1.0213], device='cuda:0')\n",
                        "R: tensor([1.2639, 0.8811, 0.8410, 0.9465, 1.0097, 1.0425, 1.6608, 0.9957, 0.8190,\n",
                        "        1.0213], device='cuda:0')\n",
                        "Epoch 11:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.254, val_loss=1.500, train_loss_epoch=0.246]        R: tensor([0.6470, 1.0353, 1.5341, 0.9631, 0.7711, 1.4068, 0.8961, 0.8484, 0.8019,\n",
                        "        1.1468, 1.1018, 0.8632, 0.6324, 1.6731, 0.9591, 1.7066, 2.4923, 1.5836,\n",
                        "        1.4190, 0.8266, 0.6650, 3.0805, 1.6761, 1.0328, 1.5441, 0.5858, 0.8689,\n",
                        "        1.4855, 0.8803, 1.7985, 0.5688, 0.8148, 1.4857, 1.1763, 1.5853, 0.2848,\n",
                        "        0.4561, 0.7029, 2.2211, 0.9345, 0.9044, 0.5586, 0.9748, 1.2918, 1.3518,\n",
                        "        2.4513, 0.4002, 0.5734, 1.9487, 0.4272, 1.3612, 0.8891, 0.6774, 2.3972,\n",
                        "        0.6433, 1.0645, 1.5625, 1.9045, 0.8998, 0.9601, 0.8949, 0.6389, 2.2613,\n",
                        "        0.7823], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 11:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 13.64it/s, train_loss_step=0.193, val_loss=1.500, train_loss_epoch=0.246]R: tensor([0.3017, 1.5250, 2.8250, 0.8897, 0.4192, 0.4466, 0.4358, 2.2436, 0.6188,\n",
                        "        0.8560, 1.0220, 1.2160, 0.6455, 1.6877, 1.1479, 0.9504],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 20.21it/s, train_loss_step=0.316, val_loss=1.500, train_loss_epoch=0.246]R: tensor([1.2378, 0.8680, 0.7661, 0.9146, 1.0066, 0.9793, 1.6479, 0.9517, 0.7621,\n",
                        "        0.9788], device='cuda:0')\n",
                        "R: tensor([1.2378, 0.8680, 0.7661, 0.9146, 1.0066, 0.9793, 1.6479, 0.9517, 0.7621,\n",
                        "        0.9788], device='cuda:0')\n",
                        "Epoch 12:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.316, val_loss=1.510, train_loss_epoch=0.218]        R: tensor([0.8762, 0.9406, 1.5531, 0.8409, 1.4094, 1.5095, 0.5483, 1.4548, 1.2747,\n",
                        "        0.4395, 1.6814, 1.3992, 0.6410, 0.6107, 0.8144, 1.8997, 0.9736, 0.6682,\n",
                        "        0.9734, 0.3077, 0.9679, 1.6975, 0.5943, 0.7890, 0.7895, 1.4542, 0.5656,\n",
                        "        1.7293, 0.7830, 0.8272, 1.0100, 0.6083, 1.1314, 0.6576, 0.8200, 0.5127,\n",
                        "        0.4087, 0.6813, 0.6442, 0.6822, 1.5440, 1.4229, 0.9550, 1.2673, 0.9677,\n",
                        "        0.9963, 0.4328, 2.3557, 3.1746, 0.3769, 0.7134, 2.3903, 2.2827, 0.9315,\n",
                        "        0.8511, 2.0264, 1.6452, 0.5046, 2.0035, 2.5026, 3.0885, 0.8754, 0.8938,\n",
                        "        0.3910], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 12:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 11.77it/s, train_loss_step=0.183, val_loss=1.510, train_loss_epoch=0.218]R: tensor([1.8925, 1.0182, 0.7658, 1.3074, 0.9128, 1.4142, 1.5510, 0.3485, 2.1084,\n",
                        "        0.4515, 0.9570, 0.7943, 0.8952, 0.9128, 1.7421, 0.9891],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 17.12it/s, train_loss_step=0.314, val_loss=1.510, train_loss_epoch=0.218]R: tensor([1.1788, 0.8744, 0.7235, 0.9069, 1.0369, 0.9469, 1.7213, 0.9067, 0.7245,\n",
                        "        0.9685], device='cuda:0')\n",
                        "R: tensor([1.1788, 0.8744, 0.7235, 0.9069, 1.0369, 0.9469, 1.7213, 0.9067, 0.7245,\n",
                        "        0.9685], device='cuda:0')\n",
                        "Epoch 13:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.314, val_loss=1.470, train_loss_epoch=0.209]        R: tensor([0.7056, 3.3530, 1.0072, 1.3578, 0.6410, 0.3620, 0.8562, 1.7363, 0.7170,\n",
                        "        2.1600, 0.4140, 0.8752, 0.3385, 0.9433, 0.9285, 2.2180, 0.7531, 0.8059,\n",
                        "        1.3489, 0.7614, 0.3906, 1.5251, 1.4433, 0.5815, 1.4737, 1.5814, 2.1403,\n",
                        "        1.1233, 1.3602, 0.5569, 1.5166, 0.9742, 0.8545, 0.7294, 1.3249, 0.9163,\n",
                        "        1.7131, 0.5304, 0.8058, 0.6359, 0.5818, 0.9708, 1.0379, 1.8852, 1.3539,\n",
                        "        0.9967, 0.4617, 0.5511, 1.5998, 0.5652, 0.8541, 0.9333, 0.5142, 1.6137,\n",
                        "        2.5371, 0.9917, 0.9203, 0.9428, 1.6371, 2.2275, 1.0524, 1.6496, 0.5993,\n",
                        "        1.9683], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 13:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 12.97it/s, train_loss_step=0.179, val_loss=1.470, train_loss_epoch=0.209]R: tensor([3.0084, 0.8789, 0.6975, 0.6647, 2.1187, 2.4253, 0.4559, 1.5149, 0.4975,\n",
                        "        0.4174, 1.2388, 0.7850, 0.6790, 0.8768, 0.6780, 2.2580],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 18.89it/s, train_loss_step=0.313, val_loss=1.470, train_loss_epoch=0.209]R: tensor([1.1760, 0.9292, 0.7723, 0.9472, 1.1142, 0.9776, 1.8361, 0.9292, 0.7209,\n",
                        "        0.9978], device='cuda:0')\n",
                        "R: tensor([1.1760, 0.9292, 0.7723, 0.9472, 1.1142, 0.9776, 1.8361, 0.9292, 0.7209,\n",
                        "        0.9978], device='cuda:0')\n",
                        "Epoch 14:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.313, val_loss=1.400, train_loss_epoch=0.206]        R: tensor([0.9801, 1.7400, 1.4545, 0.6731, 2.1884, 1.5761, 0.3887, 0.8389, 1.2453,\n",
                        "        0.5675, 3.2365, 1.1107, 0.8530, 2.1879, 1.1935, 2.3737, 1.6317, 0.4800,\n",
                        "        2.6876, 0.7776, 0.6947, 0.3494, 0.9700, 1.0775, 0.8156, 1.0166, 0.3690,\n",
                        "        0.9618, 0.6650, 1.4429, 0.6322, 0.4475, 1.4603, 1.8809, 1.1134, 2.1515,\n",
                        "        0.8068, 1.3822, 2.0283, 1.0101, 1.4170, 1.2090, 0.5654, 0.9983, 0.8335,\n",
                        "        2.6422, 0.8851, 1.2978, 0.5384, 0.6414, 0.7736, 1.0260, 0.6176, 0.9973,\n",
                        "        0.5908, 1.1711, 1.5174, 0.5451, 1.0611, 1.5834, 0.8706, 3.3254, 0.5981,\n",
                        "        0.6997], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 14:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 11.39it/s, train_loss_step=0.186, val_loss=1.400, train_loss_epoch=0.206]R: tensor([1.3270, 0.7440, 2.6968, 0.5567, 0.8379, 2.0374, 1.3506, 1.7651, 1.5992,\n",
                        "        0.9489, 0.9273, 1.5493, 0.7069, 0.3421, 0.8222, 0.5854],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 17.38it/s, train_loss_step=0.299, val_loss=1.400, train_loss_epoch=0.206]R: tensor([1.1505, 0.9586, 0.8279, 1.0022, 1.1655, 1.0369, 2.0119, 0.9510, 0.7186,\n",
                        "        1.0345], device='cuda:0')\n",
                        "R: tensor([1.1505, 0.9586, 0.8279, 1.0022, 1.1655, 1.0369, 2.0119, 0.9510, 0.7186,\n",
                        "        1.0345], device='cuda:0')\n",
                        "Epoch 15:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.299, val_loss=1.330, train_loss_epoch=0.209]        R: tensor([0.9761, 1.3856, 2.1172, 1.8188, 0.9499, 1.8194, 0.5718, 3.3363, 0.7210,\n",
                        "        0.5788, 0.2947, 2.6503, 0.4389, 1.4777, 0.7261, 2.1876, 0.9881, 1.1054,\n",
                        "        1.8417, 1.1595, 0.6247, 0.6062, 0.5609, 0.3438, 2.0453, 1.0857, 1.7828,\n",
                        "        0.9917, 1.4098, 0.3763, 1.3902, 0.5570, 0.5605, 1.2149, 0.4245, 1.2688,\n",
                        "        0.7962, 3.2361, 0.7360, 0.6261, 1.0741, 2.2461, 1.5421, 1.5105, 1.8069,\n",
                        "        0.4650, 0.9152, 1.2654, 2.4339, 0.8875, 0.9513, 2.5665, 0.9478, 1.3843,\n",
                        "        0.8200, 0.8002, 1.6173, 0.6686, 0.9397, 3.1217, 0.8839, 1.1647, 1.6780,\n",
                        "        0.7709], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 15:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 12.94it/s, train_loss_step=0.179, val_loss=1.330, train_loss_epoch=0.209]R: tensor([0.8490, 2.0072, 0.8679, 1.1920, 1.6344, 1.0688, 1.3760, 0.6861, 0.7912,\n",
                        "        0.9095, 0.7912, 0.6186, 0.6313, 1.3917, 1.2785, 0.4194],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 18.16it/s, train_loss_step=0.354, val_loss=1.330, train_loss_epoch=0.209]R: tensor([1.0943, 0.9464, 0.8401, 1.0535, 1.1926, 1.0804, 2.1225, 0.9426, 0.7337,\n",
                        "        1.0816], device='cuda:0')\n",
                        "R: tensor([1.0943, 0.9464, 0.8401, 1.0535, 1.1926, 1.0804, 2.1225, 0.9426, 0.7337,\n",
                        "        1.0816], device='cuda:0')\n",
                        "Epoch 16:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.354, val_loss=1.280, train_loss_epoch=0.214]        R: tensor([1.5576, 0.3570, 3.2311, 2.1248, 0.5518, 0.9502, 0.9908, 0.4711, 1.3174,\n",
                        "        0.2868, 0.6390, 0.7967, 0.7843, 0.4632, 2.4070, 2.6231, 0.9265, 1.1533,\n",
                        "        0.3871, 1.5036, 1.4410, 2.1742, 0.7352, 0.5607, 0.7592, 0.7926, 0.9856,\n",
                        "        0.5715, 1.2638, 1.1053, 1.7882, 0.9358, 1.0796, 0.7127, 1.3037, 0.3818,\n",
                        "        0.4729, 1.8323, 2.1745, 2.0299, 0.5959, 1.1968, 3.1281, 1.1002, 0.9712,\n",
                        "        0.9819, 0.9098, 0.7469, 1.4687, 0.6044, 1.7720, 0.8478, 1.1488, 1.3276,\n",
                        "        1.3802, 0.7444, 1.2077, 1.1513, 1.6237, 1.6242, 0.6334, 0.6541, 3.3272,\n",
                        "        1.0608], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 16:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 15.64it/s, train_loss_step=0.192, val_loss=1.280, train_loss_epoch=0.214]R: tensor([1.8761, 0.3589, 1.5855, 0.7641, 1.0232, 0.6405, 0.5840, 2.7774, 1.7469,\n",
                        "        1.1607, 1.7387, 0.5531, 1.3137, 0.7033, 0.7127, 0.8827],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 21.52it/s, train_loss_step=0.191, val_loss=1.280, train_loss_epoch=0.214]R: tensor([1.0168, 0.9182, 0.7992, 1.0492, 1.1870, 1.0997, 2.1239, 0.9349, 0.7301,\n",
                        "        1.1102], device='cuda:0')\n",
                        "R: tensor([1.0168, 0.9182, 0.7992, 1.0492, 1.1870, 1.0997, 2.1239, 0.9349, 0.7301,\n",
                        "        1.1102], device='cuda:0')\n",
                        "Epoch 17:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.191, val_loss=1.260, train_loss_epoch=0.192]        R: tensor([2.0429, 0.3847, 1.7207, 1.3026, 2.5519, 0.9885, 0.9885, 0.6067, 2.1298,\n",
                        "        2.9390, 0.9755, 1.6072, 1.4396, 3.2565, 0.2665, 0.8413, 0.4738, 1.1036,\n",
                        "        0.5590, 0.6273, 1.3509, 1.3674, 1.3397, 2.3502, 0.3604, 0.5230, 1.7010,\n",
                        "        0.7155, 1.1504, 0.6358, 0.9740, 1.8184, 1.0794, 0.4977, 0.4560, 2.1167,\n",
                        "        0.4760, 3.1597, 0.8361, 2.6184, 1.2373, 0.8185, 0.7459, 0.6252, 0.6210,\n",
                        "        0.5584, 0.8779, 0.8714, 0.6302, 0.7356, 0.9503, 1.4172, 1.2729, 0.4938,\n",
                        "        0.8349, 1.8136, 0.3231, 1.0652, 1.4399, 0.7265, 0.6760, 0.6299, 0.9238,\n",
                        "        0.7187], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 17:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 14.00it/s, train_loss_step=0.170, val_loss=1.260, train_loss_epoch=0.192]R: tensor([1.7713, 0.8671, 0.9210, 2.0231, 1.8445, 0.3266, 1.2142, 0.5243, 1.4840,\n",
                        "        1.8145, 0.9378, 1.0218, 0.5551, 0.5692, 1.8991, 1.2328],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 19.66it/s, train_loss_step=0.155, val_loss=1.260, train_loss_epoch=0.192]R: tensor([0.9453, 0.9198, 0.7657, 1.0365, 1.1999, 1.1006, 2.0648, 0.9642, 0.7148,\n",
                        "        1.1242], device='cuda:0')\n",
                        "R: tensor([0.9453, 0.9198, 0.7657, 1.0365, 1.1999, 1.1006, 2.0648, 0.9642, 0.7148,\n",
                        "        1.1242], device='cuda:0')\n",
                        "Epoch 18:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.155, val_loss=1.260, train_loss_epoch=0.167]        R: tensor([0.4833, 1.1077, 2.3204, 1.3280, 1.9014, 0.6251, 0.9970, 2.2102, 0.7604,\n",
                        "        0.2526, 0.5109, 1.3827, 1.6242, 0.3089, 0.8133, 0.5183, 0.7688, 0.7348,\n",
                        "        0.3410, 1.0068, 1.9396, 0.8266, 1.8621, 0.8540, 0.6521, 0.6966, 0.7616,\n",
                        "        1.4609, 3.3448, 0.9055, 1.7738, 0.6250, 2.4589, 1.4967, 2.8511, 0.7043,\n",
                        "        0.8712, 0.9551, 0.8668, 2.7277, 0.9127, 0.4961, 1.0028, 1.2136, 0.5841,\n",
                        "        0.3243, 1.7852, 0.3483, 1.7397, 0.7280, 0.9932, 0.4479, 0.6402, 1.4839,\n",
                        "        0.5486, 1.4157, 0.5893, 0.9811, 1.6467, 1.3128, 0.4719, 0.5525, 0.5397,\n",
                        "        1.3971], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 18:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 15.52it/s, train_loss_step=0.154, val_loss=1.260, train_loss_epoch=0.167]R: tensor([0.7986, 0.5979, 1.0283, 0.9835, 1.1615, 1.9597, 0.5969, 1.5122, 1.8679,\n",
                        "        0.9340, 2.7370, 2.2008, 0.7721, 1.1458, 0.6237, 0.4936],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 21.48it/s, train_loss_step=0.164, val_loss=1.260, train_loss_epoch=0.167]R: tensor([0.9252, 0.9560, 0.7772, 1.0030, 1.2323, 1.0934, 1.8924, 1.0495, 0.6890,\n",
                        "        1.1075], device='cuda:0')\n",
                        "R: tensor([0.9252, 0.9560, 0.7772, 1.0030, 1.2323, 1.0934, 1.8924, 1.0495, 0.6890,\n",
                        "        1.1075], device='cuda:0')\n",
                        "Epoch 19:   0%|          | 0/2 [00:00<?, ?it/s, train_loss_step=0.164, val_loss=1.270, train_loss_epoch=0.156]        R: tensor([1.9879, 1.4354, 0.7788, 0.9295, 0.6580, 0.8735, 1.0566, 0.6806, 1.6608,\n",
                        "        1.4290, 0.9419, 2.2542, 0.7594, 1.3707, 1.7655, 0.6337, 1.7979, 0.5616,\n",
                        "        0.3659, 0.6940, 0.4243, 0.4595, 0.7075, 2.5554, 2.1473, 0.9699, 0.4376,\n",
                        "        1.0033, 1.5380, 0.2163, 2.0097, 3.0965, 0.9842, 3.2052, 0.6132, 0.5037,\n",
                        "        1.6065, 0.3123, 0.9825, 0.7597, 1.7357, 1.4375, 0.6433, 1.4145, 2.5143,\n",
                        "        0.5596, 1.3139, 0.5534, 0.7932, 0.6646, 1.0626, 2.2565, 0.8682, 0.4536,\n",
                        "        0.6785, 0.3088, 0.7014, 2.4465, 0.7472, 0.8714, 1.0935, 1.2505, 0.9647,\n",
                        "        1.7369], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 19:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 14.43it/s, train_loss_step=0.162, val_loss=1.270, train_loss_epoch=0.156]R: tensor([0.5082, 1.6370, 0.6929, 0.9445, 1.4613, 1.0264, 0.7878, 0.5038, 1.5224,\n",
                        "        0.5219, 0.9111, 1.2948, 0.8377, 0.8139, 1.5739, 0.5889],\n",
                        "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
                        "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 21.42it/s, train_loss_step=0.292, val_loss=1.270, train_loss_epoch=0.156]R: tensor([0.9619, 1.0228, 0.8130, 0.9899, 1.2798, 1.0908, 1.7729, 1.1521, 0.6540,\n",
                        "        1.0933], device='cuda:0')\n",
                        "R: tensor([0.9619, 1.0228, 0.8130, 0.9899, 1.2798, 1.0908, 1.7729, 1.1521, 0.6540,\n",
                        "        1.0933], device='cuda:0')\n",
                        "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.90it/s, train_loss_step=0.292, val_loss=1.290, train_loss_epoch=0.188]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.87it/s, train_loss_step=0.292, val_loss=1.290, train_loss_epoch=0.188]\n"
                    ]
                }
            ],
            "source": [
                "trainer.fit(mpnn, train_loader, val_loader)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Test results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Restoring states from the checkpoint path at /compchem/arc/users/dvik/repos/chemprop/examples/checkpoints/best-epoch=17-val_loss=1.26.ckpt\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
                        "Loaded model weights from the checkpoint at /compchem/arc/users/dvik/repos/chemprop/examples/checkpoints/best-epoch=17-val_loss=1.26.ckpt\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Testing DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]R: tensor([0.9689, 1.4270, 0.6969, 0.6685, 1.6670, 1.4069, 1.0894, 0.7493, 1.6281,\n",
                        "        0.6725], device='cuda:0')\n",
                        "Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 93.89it/s] \n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
                            "â”ƒ<span style=\"font-weight: bold\">        Test metric        </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
                            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
                            "â”‚<span style=\"color: #008080; text-decoration-color: #008080\"> test/nlogprob_enrichment  </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.45723867416381836    </span>â”‚\n",
                            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
                            "</pre>\n"
                        ],
                        "text/plain": [
                            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
                            "â”ƒ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
                            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
                            "â”‚\u001b[36m \u001b[0m\u001b[36mtest/nlogprob_enrichment \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.45723867416381836   \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
                            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "results = trainer.test(dataloaders=test_loader)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "chemprop_dev",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
