{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from chemprop.nn.predictors import (\n",
    "    RegressionFFN,\n",
    "    BinaryClassificationFFN,\n",
    "    MulticlassClassificationFFN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example output of aggregation for input to the predictor. See the aggregation notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_datapoints_in_batch = 2\n",
    "hidden_dim = 300\n",
    "example_aggregation_output = torch.randn(n_datapoints_in_batch, hidden_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The molecule representation from message passing and aggregation is fed through a feed forward network to make the final property prediction. Three basic predictors differ in the prediction task they are used for. Multiclass classification needs to know how many possible classes the targets can be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_ffn = RegressionFFN()\n",
    "binary_class_ffn = BinaryClassificationFFN()\n",
    "multi_class_ffn = MulticlassClassificationFFN(n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input dimension of the predictor defaults to the default dimension of the message passing hidden representation. If you message passing hidden dimension is different, or if you have addition datapoint descriptors, you need to change the predictor's input dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2016],\n",
       "        [-0.1791]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = RegressionFFN()\n",
    "ffn(example_aggregation_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1014],\n",
       "        [0.0284]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorter_hidden_rep = torch.randn(n_datapoints_in_batch, 3)\n",
    "example_datapoint_descriptors = torch.randn(n_datapoints_in_batch, 12)\n",
    "\n",
    "input_dim = shorter_hidden_rep.shape[1] + example_datapoint_descriptors.shape[1]\n",
    "\n",
    "ffn = RegressionFFN(input_dim=input_dim)\n",
    "ffn(torch.cat([shorter_hidden_rep, example_datapoint_descriptors], dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of tasks defaults to 1 but can be adjusted. Predictors that need to predict multiple values per task, like multiclass classification, will automatically adjust the output dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = RegressionFFN(n_tasks=4)\n",
    "ffn(example_aggregation_output).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = MulticlassClassificationFFN(n_tasks=4, n_classes=3)\n",
    "ffn(example_aggregation_output).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following hyperparameters of the predictor are customizable:\n",
    " - the hidden dimension between layer, default: 300\n",
    " - the number of layer, default 1\n",
    " - the dropout probability, default: 0.0 (i.e. no dropout)\n",
    " - which activation function, default: ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0897],\n",
       "        [-0.0634]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_ffn = RegressionFFN(hidden_dim=600, n_layers=3, dropout=0.1, activation=\"tanh\")\n",
    "custom_ffn(example_aggregation_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intermediate hidden representations can also be extracted. Note that each predictor layer consists of an activation layer, followed by dropout, followed by a linear layer. The first predictor layer only has the linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 600])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = 2\n",
    "custom_ffn.encode(example_aggregation_output, i=layer).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionFFN(\n",
       "  (ffn): MLP(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=300, out_features=600, bias=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Tanh()\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=600, out_features=600, bias=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Tanh()\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=600, out_features=600, bias=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Tanh()\n",
       "      (1): Dropout(p=0.1, inplace=False)\n",
       "      (2): Linear(in_features=600, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (criterion): MSELoss(task_weights=[[1.0]])\n",
       "  (output_transform): Identity()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_ffn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each predictor has a criterion that is used as the loss function during training. The default criterion for a predictor is defined in the predictor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'chemprop.nn.loss.MSELoss'>\n",
      "<class 'chemprop.nn.loss.BCELoss'>\n",
      "<class 'chemprop.nn.loss.CrossEntropyLoss'>\n"
     ]
    }
   ],
   "source": [
    "print(RegressionFFN._T_default_criterion)\n",
    "print(BinaryClassificationFFN._T_default_criterion)\n",
    "print(MulticlassClassificationFFN._T_default_criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A custom criterion can be given to the predictor. See the loss function notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'criterion' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['criterion'])`.\n"
     ]
    }
   ],
   "source": [
    "from chemprop.nn import MSELoss\n",
    "\n",
    "criterion = MSELoss(task_weights=torch.tensor([0.5, 1.0]))\n",
    "ffn = RegressionFFN(n_tasks=2, criterion=criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression vs. classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to using different loss functions, regression and classification predictors also differ in their tranforms of the model outputs during inference. Regression can use a scaler transform if target normalization was used during training. (See the scaling notebook for more details.) Classification uses a sigmoid (binary classification) or a softmax (multiclass) transform to keep class probability predictions between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knathan/anaconda3/envs/chemprop/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'output_transform' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['output_transform'])`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from chemprop.data import MoleculeDatapoint, MoleculeDataset\n",
    "from chemprop.nn import UnscaleTransform\n",
    "\n",
    "smis = [\"C\" * i for i in range(1, 4)]\n",
    "ys = np.random.rand(len(smis), 1)\n",
    "dataset = MoleculeDataset([MoleculeDatapoint.from_smi(smi, y) for smi, y in zip(smis, ys)])\n",
    "\n",
    "output_scaler = dataset.normalize_targets()\n",
    "output_transform = UnscaleTransform.from_standard_scaler(output_scaler)\n",
    "\n",
    "unscaled_ffn = RegressionFFN()\n",
    "scaled_ffn = RegressionFFN(output_transform=output_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0452],\n",
       "        [-0.5311]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscaled_ffn(example_aggregation_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0404],\n",
       "        [-0.1165]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_ffn(example_aggregation_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = binary_class_ffn(example_aggregation_output)\n",
    "(0 < probs).all() and (probs < 1).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other predictors coming soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta versions of predictors for uncertainty and spectral tasks will be finalized in v2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemprop.nn.predictors import (\n",
    "    MveFFN,\n",
    "    EvidentialFFN,\n",
    "    BinaryDirichletFFN,\n",
    "    MulticlassDirichletFFN,\n",
    "    SpectralFFN,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
