{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Regression - Reaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightning import pytorch as pl\n",
    "from pathlib import Path\n",
    "import os\n",
    "os.chdir('/home/labhhc2/Documents/workspace/D20/Tam/chemprop/')\n",
    "\n",
    "from chemprop import data, featurizers, models, nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change data inputs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemprop_dir = Path.cwd().parent\n",
    "input_path = chemprop_dir / \"chemprop\" / \"tests\" / \"data\" / \"reactiondatabase\" / \"data\" / \"phosphatase.csv\"\n",
    "num_workers = 0  # number of workers for dataloader. 0 means using main process for data loading\n",
    "smiles_column = 'AAM'\n",
    "target_columns = ['Conversion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAM</th>\n",
       "      <th>Conversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CH2:1]=[C:2]([O:3][P:4](=[O:5])([OH:6])[OH:7]...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CH3:1][C:2](=[O:3])[NH:4][C@@H:5]1[CH:6]([OH:...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CH3:1][C:2](=[O:3])[NH:4][C@@H:5]1[C@@H:6]([O...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CH3:1][C:2](=[O:3])[O:4][P:5](=[O:6])([OH:7])...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CH3:1][C:2]([CH3:3])([CH2:4][O:5][P:6](=[O:7]...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33349</th>\n",
       "      <td>[O:1]=[c:2]1[nH:3][cH:4][n:5][c:6]2[c:7]1[n:8]...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33350</th>\n",
       "      <td>[O:1]=[c:2]1[cH:3][cH:4][n:5]([C@@H:6]2[O:7][C...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33351</th>\n",
       "      <td>[O:1]=[c:2]1[cH:3][cH:4][n:5]([C@@H:6]2[O:7][C...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33352</th>\n",
       "      <td>[O:1]=[c:2]1[cH:3][cH:4][n:5]([C@@H:6]2[O:7][C...</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33353</th>\n",
       "      <td>[O:1]=[c:2]1[cH:3][cH:4][n:5]([C@H:6]2[CH2:7][...</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33354 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     AAM  Conversion\n",
       "0      [CH2:1]=[C:2]([O:3][P:4](=[O:5])([OH:6])[OH:7]...       0.000\n",
       "1      [CH3:1][C:2](=[O:3])[NH:4][C@@H:5]1[CH:6]([OH:...       0.000\n",
       "2      [CH3:1][C:2](=[O:3])[NH:4][C@@H:5]1[C@@H:6]([O...       0.000\n",
       "3      [CH3:1][C:2](=[O:3])[O:4][P:5](=[O:6])([OH:7])...       0.000\n",
       "4      [CH3:1][C:2]([CH3:3])([CH2:4][O:5][P:6](=[O:7]...       0.000\n",
       "...                                                  ...         ...\n",
       "33349  [O:1]=[c:2]1[nH:3][cH:4][n:5][c:6]2[c:7]1[n:8]...       0.000\n",
       "33350  [O:1]=[c:2]1[cH:3][cH:4][n:5]([C@@H:6]2[O:7][C...       0.000\n",
       "33351  [O:1]=[c:2]1[cH:3][cH:4][n:5]([C@@H:6]2[O:7][C...       0.000\n",
       "33352  [O:1]=[c:2]1[cH:3][cH:4][n:5]([C@@H:6]2[O:7][C...       0.000\n",
       "33353  [O:1]=[c:2]1[cH:3][cH:4][n:5]([C@H:6]2[CH2:7][...       0.009\n",
       "\n",
       "[33354 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input = pd.read_csv(input_path)\n",
    "df_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load smiles and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['[CH2:1]=[C:2]([O:3][P:4](=[O:5])([OH:6])[OH:7])[C:8](=[O:9])[OH:10].[OH2:11]>>[CH2:1]=[C:2]([OH:3])[C:8](=[O:9])[OH:10].[P:4](=[O:5])([OH:6])([OH:7])[OH:11]',\n",
       "        '[CH3:1][C:2](=[O:3])[NH:4][C@@H:5]1[CH:6]([OH:7])[O:8][C@H:9]([CH2:10][O:11][P:12](=[O:13])([OH:14])[OH:15])[C@@H:16]([OH:17])[C@@H:18]1[OH:19].[OH2:20]>>[CH3:1][C:2](=[O:3])[NH:4][C@@H:5]1[CH:6]([OH:7])[O:8][C@H:9]([CH2:10][OH:11])[C@@H:16]([OH:17])[C@@H:18]1[OH:19].[P:12](=[O:13])([OH:14])([OH:15])[OH:20]',\n",
       "        '[CH3:1][C:2](=[O:3])[NH:4][C@@H:5]1[C@@H:6]([OH:7])[CH2:8][C:9]([OH:10])([C:11](=[O:12])[OH:13])[O:14][C@H:15]1[C@H:16]([OH:17])[C@H:18]([OH:19])[CH2:20][O:21][P:22](=[O:23])([OH:24])[OH:25].[OH2:26]>>[CH3:1][C:2](=[O:3])[NH:4][C@@H:5]1[C@@H:6]([OH:7])[CH2:8][C:9]([OH:10])([C:11](=[O:12])[OH:13])[O:14][C@H:15]1[C@H:16]([OH:17])[C@H:18]([OH:19])[CH2:20][OH:21].[P:22](=[O:23])([OH:24])([OH:25])[OH:26]',\n",
       "        '[CH3:1][C:2](=[O:3])[O:4][P:5](=[O:6])([OH:7])[OH:8].[OH2:9]>>[CH3:1][C:2](=[O:3])[OH:4].[P:5](=[O:6])([OH:7])([OH:8])[OH:9]',\n",
       "        '[CH3:1][C:2]([CH3:3])([CH2:4][O:5][P:6](=[O:7])([OH:8])[O:9][P:10](=[O:11])([OH:12])[O:13][CH2:14][C@H:15]1[O:16][C@@H:17]([n:18]2[cH:19][n:20][c:21]3[c:22]([NH2:23])[n:24][cH:25][n:26][c:27]23)[C@H:28]([OH:29])[C@@H:30]1[O:31][P:32](=[O:33])([OH:34])[OH:35])[C@@H:36]([OH:37])[C:38](=[O:39])[NH:40][CH2:41][CH2:42][C:43](=[O:44])[NH:45][CH2:46][CH2:47][SH:48].[OH2:49]>>[CH3:1][C:2]([CH3:3])([CH2:4][O:5][P:6](=[O:7])([OH:8])[O:9][P:10](=[O:11])([OH:12])[O:13][CH2:14][C@H:15]1[O:16][C@@H:17]([n:18]2[cH:19][n:20][c:21]3[c:22]([NH2:23])[n:24][cH:25][n:26][c:27]23)[C@H:28]([OH:29])[C@@H:30]1[OH:31])[C@@H:36]([OH:37])[C:38](=[O:39])[NH:40][CH2:41][CH2:42][C:43](=[O:44])[NH:45][CH2:46][CH2:47][SH:48].[P:32](=[O:33])([OH:34])([OH:35])[OH:49]'],\n",
       "       dtype=object),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smis = df_input.loc[:, smiles_column].values\n",
    "ys = df_input.loc[:, target_columns].values\n",
    "\n",
    "smis[:5], ys[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [data.ReactionDatapoint.from_smi(smi, y) for smi, y in zip(smis, ys)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform data splitting for training, validation, and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = [d.rct for d in all_data]  # Can either split by reactants (.rct) or products (.pdt)\n",
    "train_indices, val_indices, test_indices = data.make_split_indices(mols, \"random\", (0.8, 0.1, 0.1))\n",
    "train_data, val_data, test_data = data.split_data_by_indices(\n",
    "    all_data, train_indices, val_indices, test_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the featurizer\n",
    "\n",
    "Reactions can be featurized using the ```CondensedGraphOfReactionFeaturizer``` (also labeled ```CGRFeaturizer```).\n",
    "\n",
    "\n",
    "Use ```_mode``` keyword to set the mode by which a reaction should be featurized into a ```MolGraph```.\n",
    "\n",
    "Options are can be found with ```featurizers.RxnMode.keys```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAC_PROD\n",
      "REAC_PROD_BALANCE\n",
      "REAC_DIFF\n",
      "REAC_DIFF_BALANCE\n",
      "PROD_DIFF\n",
      "PROD_DIFF_BALANCE\n"
     ]
    }
   ],
   "source": [
    "for key in featurizers.RxnMode.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = featurizers.CondensedGraphOfReactionFeaturizer(mode_=\"PROD_DIFF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ReactionDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = data.ReactionDataset(train_data, featurizer)\n",
    "scaler = train_dset.normalize_targets()\n",
    "\n",
    "val_dset = data.ReactionDataset(val_data, featurizer)\n",
    "val_dset.normalize_targets(scaler)\n",
    "test_dset = data.ReactionDataset(test_data, featurizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.build_dataloader(train_dset, num_workers=num_workers)\n",
    "val_loader = data.build_dataloader(val_dset, num_workers=num_workers, shuffle=False)\n",
    "test_loader = data.build_dataloader(test_dset, num_workers=num_workers, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Message-Passing Neural Network (MPNN) inputs here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message passing\n",
    "\n",
    "Message passing blocks must be given the shape of the featurizer's outputs.\n",
    "\n",
    "Options are `mp = nn.BondMessagePassing()` or `mp = nn.AtomMessagePassing()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdims = featurizer.shape # the dimensions of the featurizer, given as (atom_dims, bond_dims).\n",
    "mp = nn.BondMessagePassing(*fdims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassRegistry {\n",
      "    'mean': <class 'chemprop.nn.agg.MeanAggregation'>,\n",
      "    'sum': <class 'chemprop.nn.agg.SumAggregation'>,\n",
      "    'norm': <class 'chemprop.nn.agg.NormAggregation'>\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(nn.agg.AggregationRegistry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = nn.MeanAggregation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-Forward Network (FFN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassRegistry {\n",
      "    'regression': <class 'chemprop.nn.predictors.RegressionFFN'>,\n",
      "    'regression-mve': <class 'chemprop.nn.predictors.MveFFN'>,\n",
      "    'regression-evidential': <class 'chemprop.nn.predictors.EvidentialFFN'>,\n",
      "    'classification': <class 'chemprop.nn.predictors.BinaryClassificationFFN'>,\n",
      "    'classification-dirichlet': <class 'chemprop.nn.predictors.BinaryDirichletFFN'>,\n",
      "    'multiclass': <class 'chemprop.nn.predictors.MulticlassClassificationFFN'>,\n",
      "    'multiclass-dirichlet': <class 'chemprop.nn.predictors.MulticlassDirichletFFN'>,\n",
      "    'spectral': <class 'chemprop.nn.predictors.SpectralFFN'>\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(nn.PredictorRegistry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_transform = nn.UnscaleTransform.from_standard_scaler(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn = nn.RegressionFFN(output_transform=output_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassRegistry {\n",
      "    'mae': <class 'chemprop.nn.metrics.MAEMetric'>,\n",
      "    'mse': <class 'chemprop.nn.metrics.MSEMetric'>,\n",
      "    'rmse': <class 'chemprop.nn.metrics.RMSEMetric'>,\n",
      "    'bounded-mae': <class 'chemprop.nn.metrics.BoundedMAEMetric'>,\n",
      "    'bounded-mse': <class 'chemprop.nn.metrics.BoundedMSEMetric'>,\n",
      "    'bounded-rmse': <class 'chemprop.nn.metrics.BoundedRMSEMetric'>,\n",
      "    'r2': <class 'chemprop.nn.metrics.R2Metric'>,\n",
      "    'roc': <class 'chemprop.nn.metrics.BinaryAUROCMetric'>,\n",
      "    'prc': <class 'chemprop.nn.metrics.BinaryAUPRCMetric'>,\n",
      "    'accuracy': <class 'chemprop.nn.metrics.BinaryAccuracyMetric'>,\n",
      "    'f1': <class 'chemprop.nn.metrics.BinaryF1Metric'>,\n",
      "    'bce': <class 'chemprop.nn.metrics.BCEMetric'>,\n",
      "    'ce': <class 'chemprop.nn.metrics.CrossEntropyMetric'>,\n",
      "    'binary-mcc': <class 'chemprop.nn.metrics.BinaryMCCMetric'>,\n",
      "    'multiclass-mcc': <class 'chemprop.nn.metrics.MulticlassMCCMetric'>,\n",
      "    'sid': <class 'chemprop.nn.metrics.SIDMetric'>,\n",
      "    'wasserstein': <class 'chemprop.nn.metrics.WassersteinMetric'>\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(nn.metrics.MetricRegistry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_list = [nn.metrics.RMSEMetric(), nn.metrics.MAEMetric()] \n",
    "# Only the first metric is used for training and early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct MPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNN(\n",
       "  (message_passing): BondMessagePassing(\n",
       "    (W_i): Linear(in_features=134, out_features=300, bias=False)\n",
       "    (W_h): Linear(in_features=300, out_features=300, bias=False)\n",
       "    (W_o): Linear(in_features=406, out_features=300, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (tau): ReLU()\n",
       "    (V_d_transform): Identity()\n",
       "    (graph_transform): Identity()\n",
       "  )\n",
       "  (agg): MeanAggregation()\n",
       "  (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (predictor): RegressionFFN(\n",
       "    (ffn): MLP(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ReLU()\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Linear(in_features=300, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (criterion): MSELoss(task_weights=[[1.0]])\n",
       "    (output_transform): UnscaleTransform()\n",
       "  )\n",
       "  (X_d_transform): Identity()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpnn = models.MPNN(mp, agg, ffn, batch_norm, metric_list)\n",
    "mpnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    logger=False,\n",
    "    enable_checkpointing=True,  # Use `True` if you want to save model checkpoints. The checkpoints will be saved in the `checkpoints` folder.\n",
    "    enable_progress_bar=True,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=20,  # number of epochs to train for\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti SUPER') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/labhhc2/anaconda3/envs/synprop/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/labhhc2/Documents/workspace/D20/Tam/chemprop/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/home/labhhc2/anaconda3/envs/synprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
      "\n",
      "  | Name            | Type               | Params | Mode \n",
      "---------------------------------------------------------------\n",
      "0 | message_passing | BondMessagePassing | 252 K  | train\n",
      "1 | agg             | MeanAggregation    | 0      | train\n",
      "2 | bn              | BatchNorm1d        | 600    | train\n",
      "3 | predictor       | RegressionFFN      | 90.6 K | train\n",
      "4 | X_d_transform   | Identity           | 0      | train\n",
      "---------------------------------------------------------------\n",
      "343 K     Trainable params\n",
      "0         Non-trainable params\n",
      "343 K     Total params\n",
      "1.374     Total estimated model params size (MB)\n",
      "21        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/labhhc2/anaconda3/envs/synprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 417/417 [00:15<00:00, 27.60it/s, train_loss=0.727, val_loss=0.953]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 417/417 [00:15<00:00, 27.58it/s, train_loss=0.727, val_loss=0.953]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(mpnn, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/labhhc2/anaconda3/envs/synprop/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 53/53 [00:01<00:00, 34.07it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      " batch_averaged_test/mae    0.09829461574554443\n",
      "batch_averaged_test/rmse    0.13805873692035675\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'batch_averaged_test/rmse': 0.13805873692035675,\n",
       "  'batch_averaged_test/mae': 0.09829461574554443}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trainer.test(mpnn, test_loader)\n",
    "results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synprop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
